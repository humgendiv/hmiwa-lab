{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6f6cc23-d11a-41a2-a717-efd9f4ecc429",
   "metadata": {},
   "source": [
    "# Basic Tutorial for Polygenic Risk Score Analysis\n",
    "\n",
    "https://choishingwan.github.io/PRS-Tutorial/\n",
    "\n",
    "今回はこれにしたがって動かしてみます"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a4b1d0-87be-4f43-b12a-d716ef8b84ed",
   "metadata": {},
   "source": [
    "## 1. QC of Base Data\n",
    "\n",
    "### Obtaining the base data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49458777-bf33-43c8-9f13-3763f95f5ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-11-13 01:50:18--  https://drive.google.com/u/0/uc?id=1RWjk49QNZj9zvJHc9X_wyZ51fdy6xQjv&export=download\n",
      "Resolving drive.google.com (drive.google.com)... 172.217.26.238, 2404:6800:4004:801::200e\n",
      "Connecting to drive.google.com (drive.google.com)|172.217.26.238|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://drive.google.com/uc?id=1RWjk49QNZj9zvJHc9X_wyZ51fdy6xQjv&export=download [following]\n",
      "--2023-11-13 01:50:18--  https://drive.google.com/uc?id=1RWjk49QNZj9zvJHc9X_wyZ51fdy6xQjv&export=download\n",
      "Reusing existing connection to drive.google.com:443.\n",
      "HTTP request sent, awaiting response... 303 See Other\n",
      "Location: https://doc-08-bo-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/i0q63k8tmcl049rvs9m96mh6os68hsoe/1699807800000/00063656433649606985/*/1RWjk49QNZj9zvJHc9X_wyZ51fdy6xQjv?e=download&uuid=e2ae40ef-b410-41e3-ae97-aa5399397f4c [following]\n",
      "Warning: wildcards not supported in HTTP.\n",
      "--2023-11-13 01:50:19--  https://doc-08-bo-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/i0q63k8tmcl049rvs9m96mh6os68hsoe/1699807800000/00063656433649606985/*/1RWjk49QNZj9zvJHc9X_wyZ51fdy6xQjv?e=download&uuid=e2ae40ef-b410-41e3-ae97-aa5399397f4c\n",
      "Resolving doc-08-bo-docs.googleusercontent.com (doc-08-bo-docs.googleusercontent.com)... 172.217.31.161, 2404:6800:4004:80c::2001\n",
      "Connecting to doc-08-bo-docs.googleusercontent.com (doc-08-bo-docs.googleusercontent.com)|172.217.31.161|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 22609185 (22M) [application/x-gzip]\n",
      "Saving to: ‘Height.gwas.txt.gz’\n",
      "\n",
      "Height.gwas.txt.gz  100%[===================>]  21.56M  37.5MB/s    in 0.6s    \n",
      "\n",
      "2023-11-13 01:50:21 (37.5 MB/s) - ‘Height.gwas.txt.gz’ saved [22609185/22609185]\n",
      "\n",
      "\u001b[0m\u001b[01;31mHeight.gwas.txt.gz\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#データのダウンロード\n",
    "cd ~/hmiwa/hmiwa-lab/d_20231023/03_231113_TutorialPRS\n",
    "mkdir -p data\n",
    "cd data\n",
    "wget \"https://drive.google.com/u/0/uc?id=1RWjk49QNZj9zvJHc9X_wyZ51fdy6xQjv&export=download\" -O Height.gwas.txt.gz\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d7b37b-3e98-436f-a643-90a8172611e7",
   "metadata": {},
   "source": [
    "注）google ドライブからwgetで取得するヒントはこちら\n",
    "\n",
    "https://qiita.com/namakemono/items/c963e75e0af3f7eed732"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c225c8-e4ea-4976-b75c-fbb47a3d38a9",
   "metadata": {},
   "source": [
    "### Reading the base data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a68c4bfd-beb3-41b5-bbc5-fb634ee0e9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHR\tBP\tSNP\tA1\tA2\tN\tSE\tP\tOR\tINFO\tMAF\n",
      "1\t756604\trs3131962\tA\tG\t388028\t0.00301666\t0.483171\t0.997886915712657\t0.890557941364774\t0.369389592764921\n",
      "1\t768448\trs12562034\tA\tG\t388028\t0.00329472\t0.834808\t1.00068731609353\t0.895893511351165\t0.336845754096289\n",
      "1\t779322\trs4040617\tG\tA\t388028\t0.00303344\t0.42897\t0.997603556067569\t0.897508290615237\t0.377368010940814\n",
      "1\t801536\trs79373928\tG\tT\t388028\t0.00841324\t0.808999\t1.00203569922793\t0.908962856432993\t0.483212245374095\n",
      "1\t808631\trs11240779\tG\tA\t388028\t0.00242821\t0.590265\t1.00130832511154\t0.893212523690488\t0.450409558999587\n",
      "1\t809876\trs57181708\tG\tA\t388028\t0.00336785\t0.71475\t1.00123165786833\t0.923557624081969\t0.499743932656759\n",
      "1\t835499\trs4422948\tG\tA\t388028\t0.0023758\t0.710884\t0.999119752645202\t0.906437735120596\t0.481016005816168\n",
      "1\t838555\trs4970383\tA\tC\t388028\t0.00235773\t0.150993\t0.996619945289758\t0.907716506801574\t0.327164029672754\n",
      "1\t840753\trs4970382\tC\tT\t388028\t0.00207377\t0.199967\t0.99734567895614\t0.914602590137255\t0.498936220426316\n",
      "\n",
      "gzip: stdout: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "#なかみの確認\n",
    "gunzip -c Height.gwas.txt.gz | head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456cc74c-8186-4f8e-a6b4-0d82211957a9",
   "metadata": {},
   "source": [
    "列の内容について：（サイトから引用）\n",
    "* CHR: The chromosome in which the SNP resides\n",
    "* BP: Chromosomal co-ordinate of the SNP\n",
    "* SNP: SNP ID, usually in the form of rs-ID\n",
    "* A1: The effect allele of the SNP\n",
    "* A2: The non-effect allele of the SNP\n",
    "* N: Number of samples used to obtain the effect size estimate\n",
    "* SE: The standard error (SE) of the effect size esimate\n",
    "* P: The P-value of association between the SNP genotypes and the base phenotype\n",
    "* OR: The effect size estimate of the SNP, if the outcome is binary/case-control. If the outcome is continuous or treated as continuous then this will usually be BETA\n",
    "* INFO: The imputation information score\n",
    "* MAF: The minor allele frequency (MAF) of the SNP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108be9b8-7e80-47a3-b118-52a3ba5309f1",
   "metadata": {},
   "source": [
    "### QC checklist: Base data\n",
    "\n",
    "#### Heritability check\n",
    "\n",
    "We recommend that PRS analyses are performed on base data with a chip-heritability estimate h2snp>0.05. The chip-heritability of a GWAS can be estimated using e.g. LD Score Regression (LDSC). Our height GWAS data are simulated to have a chip-heritability much greater than 0.05 and so we can move on to the next QC step.\n",
    "\n",
    "PRS解析はチップヘリタビリティ推定値h2snp>0.05のベースデータで行うことを推奨する。GWASのチップヘリタビリティーは、例えばLD Score Regression (LDSC)を用いて推定することができる。我々の身長GWASデータは、0.05よりはるかに大きいチップヘリタビリティーを持つようにシミュレートされているので、次のQCステップに進むことができる。\n",
    "\n",
    "#### Effect allele\n",
    "\n",
    "It is important to know which allele is the effect allele and which is the non-effect allele for PRS association results to be in the correct direction.\n",
    "\n",
    "PRSの関連結果を正しい方向に導くためには、どの対立遺伝子が効果対立遺伝子で、どの対立遺伝子が非効果対立遺伝子かを知ることが重要である。\n",
    "\n",
    ">Some GWAS results files do not make clear which allele is the effect allele and which is the non-effect allele. If the incorrect assumption is made in computing the PRS, then the effect of the PRS in the target data will be in the wrong direction.\n",
    ">\n",
    ">GWASの結果ファイルの中には、どの対立遺伝子が効果対立遺伝子で、どの対立遺伝子が非効果対立遺伝子なのかを明確にしていないものがある。PRSを計算する際に間違った仮定がなされると、対象データにおけるPRSの効果は間違った方向になる。\n",
    ">\n",
    ">To avoid misleading conclusions the effect allele from the base (GWAS) data must be known.\n",
    ">\n",
    ">誤解を招く結論を避けるためには、ベース（GWAS）データからの効果対立遺伝子を知っていなければならない。\n",
    "\n",
    "#### File transfer\n",
    "\n",
    "A common problem is that the downloaded base data file can be corrupted during download, which can cause PRS software to crash or to produce errors in results. However, a md5sum hash is generally included in files so that file integrity can be checked. The following command performs this md5sum check:\n",
    "\n",
    "よくある問題は、ダウンロードしたベースデータファイルがダウンロード中に破損し、PRSソフトウェアがクラッシュしたり、結果にエラーが出ることです。しかし、ファイルの完全性をチェックできるように、一般的にファイルにはmd5sumハッシュが含まれています。次のコマンドは、このmd5sumチェックを実行します："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8877ad26-193d-4954-ba79-9b800d606b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2b15fb6a2bbbe7ef49f67959b43b160  Height.gwas.txt.gz\n"
     ]
    }
   ],
   "source": [
    "md5sum Height.gwas.txt.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bedcda-8ff4-4d4b-bf5c-09a8ae2e60aa",
   "metadata": {},
   "source": [
    "if the file is intact, then md5sum generates a string of characters, which in this case should be: a2b15fb6a2bbbe7ef49f67959b43b160. If a different string is generated, then the file is corrupted.\n",
    "\n",
    "ファイルが無傷の場合、md5sumは文字列を生成し、この場合a2b15fb6a2bbbe7ef49f67959b43b160となる。異なる文字列が生成された場合、ファイルは壊れている。\n",
    "\n",
    "#### Genome build\n",
    "\n",
    "The height summary statistic are on the same genome build as the target data that we will be using. You must check that your base and target data are on the same genome build, and if they are not then use a tool such as LiftOver to make the builds consistent across the data sets.\n",
    "\n",
    "高さの要約統計量は、これから使用するターゲットデータと同じゲノムビルドにあります。ベースデータとターゲットデータが同じゲノムビルド上にあることを確認し、もしそうでない場合は、LiftOverのようなツールを使ってデータセット間でビルドを一貫させる必要があります。\n",
    "\n",
    "LiftOver:https://genome.ucsc.edu/cgi-bin/hgLiftOver\n",
    "\n",
    "#### Standard GWAS QC\n",
    "\n",
    "As described in the paper, both the base and target data should be subjected to the standard stringent QC steps performed in GWAS. If the base data have been obtained as summary statistics from a public source, then the typical QC steps that you will be able to perform on them are to filter the SNPs according to INFO score and MAF. SNPs with low minor allele frequency (MAF) or imputation information score (INFO) are more likely to generate false positive results due to their lower statistical power (and higher probability of genotyping errors in the case of low MAF). Therefore, SNPs with low MAF and INFO are typically removed before performing downstream analyses. We recommend removing SNPs with MAF < 1% and INFO < 0.8 (with very large base sample sizes these thresholds could be reduced if sensitivity checks indicate reliable results). These SNP filters can be achieved using the following code:\n",
    "\n",
    "論文に記載されているように、ベースデータとターゲットデータの両方は、GWASで実行される標準的な厳格なQCステップに従うべきである。もしベースデータが公開されているソースから要約統計として取得されたものであれば、それに対して実行できる典型的なQCステップは、INFOスコアとMAFに従ってSNPをフィルタリングすることである。マイナーアレル頻度（MAF）またはインピュテーション情報スコア（INFO）が低いSNPは、統計的検出力が低い（MAFが低い場合はジェノタイピングエラーの確率が高い）ため、偽陽性の結果を生成する可能性が高くなります。したがって、MAFやINFOが低いSNPは、ダウンストリーム解析を行う前に除去するのが一般的である。MAF＜1％、INFO＜0.8のSNPを除去することを推奨する（ベースサンプルサイズが非常に大きい場合、感度のチェックで信頼できる結果が示されれば、これらの閾値を下げることができる）。これらのSNPフィルターは以下のコードで実現できます："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "083b5c6d-1b67-4e60-911f-08de1cd36ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gunzip -c Height.gwas.txt.gz |\\\n",
    "awk 'NR==1 || ($11 > 0.01) && ($10 > 0.8) {print}' |\\\n",
    "gzip  > Height.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f6ce8f8-c9b2-4e7f-95c9-23815d2da369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;31mHeight.gwas.txt.gz\u001b[0m  \u001b[01;31mHeight.gz\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f574e48-eb1b-4a01-9847-35a775e4107c",
   "metadata": {},
   "source": [
    "The bash code above does the following:\n",
    "\n",
    "1. Decompresses and reads the Height.gwas.txt.gz file\n",
    "2. Prints the header line (NR==1)\n",
    "3. Prints any line with MAF above 0.01 (\\$11 because the eleventh column of the file contains the MAF information)\n",
    "4. Prints any line with INFO above 0.8 (\\$10 because the tenth column of the file contains the INFO information)\n",
    "5. Compresses and writes the results to Height.gz\n",
    "\n",
    "#### Mismatching SNPs\n",
    "\n",
    "SNPs that have mismatching alleles reported in the base and target data are either resolvable by \"strand-flipping\" the alleles to their complementary alleles in e.g. the target data, such as for a SNP with A/C in the base data and G/T in the target, or non-resolvable, such as for a SNP with C/G in the base and C/T in the target. Most polygenic score software perform strand-flipping automatically for SNPs that are resolvable, and remove non-resolvable mismatching SNPs.\n",
    "\n",
    "ベースデータとターゲットデータで報告された対立遺伝子が不一致のSNPは、例えばベースデータでA/C、ターゲットデータでG/TのSNPのように、ターゲットデータで対立遺伝子を相補的な対立遺伝子に \"ストランドフリップ \"することによって解決可能か、あるいはベースデータでC/G、ターゲットデータでC/TのSNPのように解決不可能かのいずれかである。ほとんどの多遺伝子スコアソフトは、解決可能なSNPに対しては自動的にストランドフリッピングを行い、解決不可能なミスマッチSNPは削除する。\n",
    "\n",
    "Since we need the target data to know which SNPs have mismatching alleles, we will perform this strand-flipping in the target data.\n",
    "\n",
    "どのSNPがミスマッチした対立遺伝子を持つかを知るためにはターゲットデータが必要なので、このストランドフリッピングをターゲットデータで行う。\n",
    "\n",
    "#### Duplicate SNPs\n",
    "\n",
    "If an error has occurred in the generation of the base data then there may be duplicated SNPs in the base data file. Most PRS software do not allow duplicated SNPs in the base data input and thus they should be removed, using a command such as the one below:\n",
    "\n",
    "ベースデータ作成時にエラーが発生した場合、ベースデータファイル中に重複した SNP が存在する可能性がある。ほとんどのPRSソフトウェアでは、重複SNPのベースデータ入力を許可していないため、以下のようなコマンドを使用して、重複SNPを削除する必要があります："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a770ee0-de7d-4848-8038-12371be99592",
   "metadata": {},
   "outputs": [],
   "source": [
    "gunzip -c Height.gz |\\\n",
    "awk '{seen[$3]++; if(seen[$3]==1){ print}}' |\\\n",
    "gzip - > Height.nodup.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9512fb4c-a47a-484b-8437-f79cc104a5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;31mHeight.gwas.txt.gz\u001b[0m  \u001b[01;31mHeight.gz\u001b[0m  \u001b[01;31mHeight.nodup.gz\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4dad12-a617-4bf9-91d0-3dd3a850c519",
   "metadata": {},
   "source": [
    "The above command does the following:\n",
    "\n",
    "1. Decompresses and reads the Height.gz file\n",
    "2. Count number of time SNP ID was observed, assuming the third column contian the SNP ID (seen[$3]++). If this is the first time seeing this SNP ID, print it.\n",
    "3. Compresses and writes the results to Height.nodup.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afa86e60-78ba-4fa8-a66d-c7008fb3d25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height.gz\n",
      "CHR\tBP\tSNP\tA1\tA2\tN\tSE\tP\tOR\tINFO\tMAF\n",
      "1\t756604\trs3131962\tA\tG\t388028\t0.00301666\t0.483171\t0.997886915712657\t0.890557941364774\t0.369389592764921\n",
      "1\t768448\trs12562034\tA\tG\t388028\t0.00329472\t0.834808\t1.00068731609353\t0.895893511351165\t0.336845754096289\n",
      "1\t779322\trs4040617\tG\tA\t388028\t0.00303344\t0.42897\t0.997603556067569\t0.897508290615237\t0.377368010940814\n",
      "1\t801536\trs79373928\tG\tT\t388028\t0.00841324\t0.808999\t1.00203569922793\t0.908962856432993\t0.483212245374095\n",
      "\n",
      "gzip: stdout: Broken pipe\n",
      "count:529496\n",
      "Height.nodup.gz\n",
      "CHR\tBP\tSNP\tA1\tA2\tN\tSE\tP\tOR\tINFO\tMAF\n",
      "1\t756604\trs3131962\tA\tG\t388028\t0.00301666\t0.483171\t0.997886915712657\t0.890557941364774\t0.369389592764921\n",
      "1\t768448\trs12562034\tA\tG\t388028\t0.00329472\t0.834808\t1.00068731609353\t0.895893511351165\t0.336845754096289\n",
      "1\t779322\trs4040617\tG\tA\t388028\t0.00303344\t0.42897\t0.997603556067569\t0.897508290615237\t0.377368010940814\n",
      "1\t801536\trs79373928\tG\tT\t388028\t0.00841324\t0.808999\t1.00203569922793\t0.908962856432993\t0.483212245374095\n",
      "\n",
      "gzip: stdout: Broken pipe\n",
      "count:529494\n"
     ]
    }
   ],
   "source": [
    "echo \"Height.gz\"\n",
    "gunzip -c Height.gz | head -n 5\n",
    "echo \"count:\"`gunzip -c Height.gz | wc | awk '{print $1}'`\n",
    "echo \"Height.nodup.gz\"\n",
    "gunzip -c Height.nodup.gz | head -n 5\n",
    "echo \"count:\"`gunzip -c Height.nodup.gz | wc | awk '{print $1}'`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34295012-8314-4b7a-8add-e8938d4fea0a",
   "metadata": {},
   "source": [
    "#### Ambiguous SNPs\n",
    "\n",
    "If the base and target data were generated using different genotyping chips and the chromosome strand (+/-) that was used for either is unknown, then it is not possible to pair-up the alleles of ambiguous SNPs (i.e. those with complementary alleles, either C/G or A/T SNPs) across the data sets, because it will be unknown whether the base and target data are referring to the same allele or not. While allele frequencies could be used to infer which alleles are on the same strand, the accuracy of this could be low for SNPs with MAF close to 50% or when the base and target data are from different populations. Therefore, we recommend removing all ambiguous SNPs to avoid introducing this potential source of systematic error.\n",
    "\n",
    "ベースとターゲットのデータが異なるジェノタイピングチップを用いて作成され、どちらかに使用された染色体鎖（+/-）が不明である場合、ベースとターゲットのデータが同じ対立遺伝子を参照しているかどうかが不明であるため、データセット間であいまいなSNP（すなわち、相補的な対立遺伝子を持つSNP、C/GまたはA/TのSNP）の対立遺伝子をペアリングすることはできない。どの対立遺伝子が同じ鎖上にあるのかを推測するために対立遺伝子頻度を用いることもできるが、MAFが50%に近いSNPや、ベースデータとターゲットデータが異なる集団のものである場合、その精度は低くなる可能性がある。したがって、このような系統誤差の原因となる可能性を避けるために、あいまいなSNPはすべて削除することを推奨する。\n",
    "\n",
    "Ambiguous SNPs can be removed in the base data and then there will be no such SNPs in the subsequent analyses, since analyses are performed only on SNPs that overlap between the base and target data. Nonambiguous SNPs can be retained using the following:\n",
    "\n",
    "曖昧なSNPはベースデータから削除することができ、ベースデータとターゲットデータの間で重複するSNPに対してのみ解析が行われるため、その後の解析ではそのようなSNPは存在しない。曖昧でないSNPは以下の方法で残すことができる："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95f3bb09-e8e8-43b0-873a-d507d63f10e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gunzip -c Height.nodup.gz |\\\n",
    "awk '!( ($4==\"A\" && $5==\"T\") || \\\n",
    "        ($4==\"T\" && $5==\"A\") || \\\n",
    "        ($4==\"G\" && $5==\"C\") || \\\n",
    "        ($4==\"C\" && $5==\"G\")) {print}' |\\\n",
    "    gzip > Height.QC.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4fad4ff-9cb9-4d81-882f-5da64164489d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499618\n"
     ]
    }
   ],
   "source": [
    "gunzip -c Height.QC.gz | wc | awk '{print $1}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90475cb-b188-4256-9de9-f7e637457128",
   "metadata": {},
   "source": [
    "#### Sex chromosomes\n",
    "\n",
    "Sometimes sample mislabelling can occur, which may lead to invalid results. One indication of a mislabelled sample is a difference between reported sex and that indicated by the sex chromosomes. While this may be due to a difference in sex and gender identity, it could also reflect mislabeling of samples or misreporting and, thus, individuals in which there is a mismatch between biological and reported sex are typically removed. See the Target Data section in which a sex-check is performed.\n",
    "\n",
    "時には検体の誤標識が起こり、無効な結果につながることがあります。誤ラベリングされたサンプルの兆候の一つは、報告された性と性染色体が示す性との違いである。これは性別や性自認の違いによるものかもしれないが、サンプルの誤ラベリングや報告ミスを反映している可能性もあるため、生物学的性別と報告された性別が不一致の個体は通常除外される。性別チェックが行われる「対象データ」の項を参照のこと。\n",
    "\n",
    "#### Sample overlap\n",
    "\n",
    "Since the target data were simulated there are no overlapping samples between the base and target data here (see the relevant section of the paper for discussion of the importance of avoiding sample overlap).\n",
    "\n",
    "ターゲットデータはシミュレートされたものであるため、ベースデータとターゲットデータの間に重複するサンプルはない（サンプルの重複を避けることの重要性については、論文の関連セクションを参照）。\n",
    "\n",
    "#### Relatedness\n",
    "\n",
    "Closely related individuals within and between the base and the target data may lead to overfitted results, limiting the generalizability of the results (see the relevant sections of the paper). Relatedness within the target data is tested in the Target Data section.\n",
    "\n",
    "ベースデータ内およびターゲットデータ間で密接に関連する個体は、結果の一般化可能性を制限する過剰適合につながる可能性がある（論文の関連セクションを参照）。ターゲットデータ内の関連性は、ターゲットデータのセクションでテストされます。\n",
    "\n",
    "**The Height.QC.gz base data are now ready for using in downstream analyses.**\n",
    "\n",
    "これで、Height.QC.gzベースデータは、下流の解析で使用する準備が整いました。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d80e481-2c3a-474b-9aa4-6c430dd05339",
   "metadata": {},
   "source": [
    "## 2. QC of Target Data\n",
    "\n",
    "### Obtaining the target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e21b6ae7-a34c-4ce1-9430-19d08b3f5f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 36.6M  100 36.6M    0     0  7245k      0  0:00:05  0:00:05 --:--:-- 9962k\n",
      "\u001b[0m\u001b[01;31mEUR.zip\u001b[0m  \u001b[01;31mHeight.gwas.txt.gz\u001b[0m  \u001b[01;31mHeight.gz\u001b[0m  \u001b[01;31mHeight.nodup.gz\u001b[0m  \u001b[01;31mHeight.QC.gz\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#データのダウンロード\n",
    "#https://drive.google.com/u/0/uc?id=1uhJR_3sn7RA8U5iYQbcmTp6vFdQiF4F2&export=download\n",
    "FILE_ID=1uhJR_3sn7RA8U5iYQbcmTp6vFdQiF4F2\n",
    "FILE_NAME=EUR.zip\n",
    "curl -sc /tmp/cookie \"https://drive.google.com/uc?export=download&id=${FILE_ID}\" > /dev/null\n",
    "CODE=\"$(awk '/_warning_/ {print $NF}' /tmp/cookie)\"  \n",
    "curl -Lb /tmp/cookie \"https://drive.google.com/uc?export=download&confirm=${CODE}&id=${FILE_ID}\" -o ${FILE_NAME}\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1de5565-c19d-4e0a-b0c3-9bfe60bc9fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EUR.zip: Zip archive data, at least v2.0 to extract, compression method=deflate\n",
      "Archive:  EUR.zip\n",
      "  inflating: EUR.bed                 \n",
      "  inflating: EUR.bim                 \n",
      "  inflating: EUR.cov                 \n",
      "  inflating: EUR.fam                 \n",
      "  inflating: EUR.height              \n",
      "EUR.bed  EUR.cov  EUR.height  \u001b[0m\u001b[01;31mHeight.gwas.txt.gz\u001b[0m  \u001b[01;31mHeight.nodup.gz\u001b[0m\n",
      "EUR.bim  EUR.fam  \u001b[01;31mEUR.zip\u001b[0m     \u001b[01;31mHeight.gz\u001b[0m           \u001b[01;31mHeight.QC.gz\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "file EUR.zip\n",
    "unzip EUR.zip\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995f20c5-26db-4234-ad12-42eef2e23f96",
   "metadata": {},
   "source": [
    "### QC checklist: Target data\n",
    "#### Sample size\n",
    "We recommend that users only perform PRS analyses on target data of at least 100 individuals. The sample size of our target data here is 503 individuals.\n",
    "\n",
    "少なくとも100人以上の対象データに対してのみPRS分析を行うことを推奨する。ここでの対象データのサンプルサイズは503人である。\n",
    "#### File transfer\n",
    "Usually we do not need to download and transfer the target data file because it is typically generated locally. However, the file should contain an md5sum code in case we send the data file to collaborators who may want to confirm that the file has not changed during the transfer.\n",
    "\n",
    "通常、対象のデータファイルはローカルで生成されるため、ダウンロードして転送する必要はない。しかし、転送中にファイルが変更されていないことを確認したい共同研究者にデータファイルを送る場合に備えて、ファイルにはmd5sumコードを含める必要がある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82188419-adb4-4319-ad89-9e67a61038df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98bcef133f683b1272d3ea5f97742e0e  EUR.bed\n",
      "6b286002904880055a9c94e01522f059  EUR.bim\n",
      "85ed18288c708e095385418517e9c3bd  EUR.cov\n",
      "e7b856f0c7bcaffc8405926d08386e97  EUR.fam\n",
      "dd445ce969a81cded20da5c88b82d4df  EUR.height\n",
      "833aa8ee3a4d9fb591ed61ba44eebe1b  EUR.zip\n"
     ]
    }
   ],
   "source": [
    "md5sum EUR*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d9b574-60a1-47c3-af63-3c58839e6812",
   "metadata": {},
   "source": [
    "#### Genome build\n",
    "As stated in the base data section, the genome build for our base and target data is the same, as it should be.\n",
    "\n",
    "ベースデータのセクションで述べたように、ベースデータとターゲットデータのゲノムビルドは同じである。\n",
    "#### Standard GWAS QC\n",
    "The target data must be quality controlled to at least the standards implemented in GWAS studies, e.g. removing SNPs with low genotyping rate, low minor allele frequency, out of Hardy-Weinberg Equilibrium, removing individuals with low genotyping rate (see Marees et al).The following plink command applies some of these QC metrics to the target data:\n",
    "\n",
    "対象データは、少なくともGWAS研究で実施されている基準で品質管理されていなければならない。例えば、ジェノタイピング率が低いSNP、マイナーアレル頻度が低いSNP、ハーディーワインベルグ平衡から外れたSNP、ジェノタイピング率が低い個体の除去などである（Marees et alを参照）。以下のplinkコマンドは、これらのQCメトリクスの一部を対象データに適用する："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4e7ac6e-5a9f-488d-b089-e62fdd2f9a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLINK v1.90b7 64-bit (16 Jan 2023)             www.cog-genomics.org/plink/1.9/\n",
      "(C) 2005-2023 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to EUR.QC.log.\n",
      "Options in effect:\n",
      "  --bfile EUR\n",
      "  --geno 0.01\n",
      "  --hwe 1e-6\n",
      "  --maf 0.01\n",
      "  --make-just-fam\n",
      "  --mind 0.01\n",
      "  --out EUR.QC\n",
      "  --write-snplist\n",
      "\n",
      "257564 MB RAM detected; reserving 128782 MB for main workspace.\n",
      "551892 variants loaded from .bim file.\n",
      "503 people (240 males, 263 females) loaded from .fam.\n",
      "14 people removed due to missing genotype data (--mind).\n",
      "IDs written to EUR.QC.irem .\n",
      "Using 1 thread (no multithreaded calculations invoked).\n",
      "Before main variant filters, 489 founders and 0 nonfounders present.\n",
      "Calculating allele frequencies... 10111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989 done.\n",
      "Warning: 1806 het. haploid genotypes present (see EUR.QC.hh ); many commands\n",
      "treat these as missing.\n",
      "Total genotyping rate in remaining samples is 0.999816.\n",
      "5353 variants removed due to missing genotype data (--geno).\n",
      "Warning: --hwe observation counts vary by more than 10%, due to the X\n",
      "chromosome.  You may want to use a less stringent --hwe p-value threshold for X\n",
      "chromosome variants.\n",
      "--hwe: 944 variants removed due to Hardy-Weinberg exact test.\n",
      "5061 variants removed due to minor allele threshold(s)\n",
      "(--maf/--max-maf/--mac/--max-mac).\n",
      "540534 variants and 489 people pass filters and QC.\n",
      "Note: No phenotypes present.\n",
      "List of variant IDs written to EUR.QC.snplist .\n",
      "--make-just-fam to EUR.QC.fam ... done.\n"
     ]
    }
   ],
   "source": [
    "plink \\\n",
    "    --bfile EUR \\\n",
    "    --maf 0.01 \\\n",
    "    --hwe 1e-6 \\\n",
    "    --geno 0.01 \\\n",
    "    --mind 0.01 \\\n",
    "    --write-snplist \\\n",
    "    --make-just-fam \\\n",
    "    --out EUR.QC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315553de-8886-4f81-9c9e-742bac5aa9eb",
   "metadata": {},
   "source": [
    ">Normally, we can generate a new genotype file using the new sample list. However, this will use up a lot of storage space. Using plink's --extract, --exclude, --keep, --remove, --make-just-fam and --write-snplist functions, we can work solely on the list of samples and SNPs without duplicating the genotype file, reducing the storage space usage.\n",
    ">\n",
    ">通常、新しいサンプルリストを用いて新しい遺伝子型ファイルを生成することができます。しかし、これでは多くの記憶容量を使うことになる。plinkの--extract関数、--exclude関数、--keep関数、--remove関数、--make-just-fam関数、--write-snplist関数を使えば、遺伝子型ファイルを複製することなく、サンプルとSNPのリストだけで作業することができ、ストレージの使用量を減らすことができる。\n",
    "\n",
    "Very high or low heterozygosity rates in individuals could be due to DNA contamination or to high levels of inbreeding. Therefore, samples with extreme heterozygosity are typically removed prior to downstream analyses.\n",
    "\n",
    "個体内のヘテロ接合率が非常に高いか低いのは、DNAのコンタミネーションや近親交配が多いためである可能性がある。従って、極端なヘテロ接合率を持つサンプルは、通常、下流の解析の前に除去される。\n",
    "\n",
    "First, we perform pruning to remove highly correlated SNPs:\n",
    "\n",
    "まず、相関性の高いSNPを除去するためにプルーニングを行う："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb0e80a0-ac1d-4c00-886a-375565111146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLINK v1.90b7 64-bit (16 Jan 2023)             www.cog-genomics.org/plink/1.9/\n",
      "(C) 2005-2023 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to EUR.QC.log.\n",
      "Options in effect:\n",
      "  --bfile EUR\n",
      "  --extract EUR.QC.snplist\n",
      "  --indep-pairwise 200 50 0.25\n",
      "  --keep EUR.QC.fam\n",
      "  --out EUR.QC\n",
      "\n",
      "257564 MB RAM detected; reserving 128782 MB for main workspace.\n",
      "551892 variants loaded from .bim file.\n",
      "503 people (240 males, 263 females) loaded from .fam.\n",
      "--extract: 540534 variants remaining.\n",
      "--keep: 489 people remaining.\n",
      "Using 1 thread (no multithreaded calculations invoked).\n",
      "Before main variant filters, 489 founders and 0 nonfounders present.\n",
      "Calculating allele frequencies... 10111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989 done.\n",
      "Warning: 1273 het. haploid genotypes present (see EUR.QC.hh ); many commands\n",
      "treat these as missing.\n",
      "Total genotyping rate in remaining samples is 0.999919.\n",
      "540534 variants and 489 people pass filters and QC.\n",
      "Note: No phenotypes present.\n",
      "Pruned 20214 variants from chromosome 1, leaving 21127.\n",
      "Pruned 20984 variants from chromosome 2, leaving 20879.\n",
      "Pruned 17463 variants from chromosome 3, leaving 17812.\n",
      "Pruned 16344 variants from chromosome 4, leaving 16690.\n",
      "Pruned 15027 variants from chromosome 5, leaving 15981.\n",
      "Pruned 20731 variants from chromosome 6, leaving 15475.\n",
      "Pruned 14046 variants from chromosome 7, leaving 14606.\n",
      "Pruned 13289 variants from chromosome 8, leaving 13667.\n",
      "Pruned 10723 variants from chromosome 9, leaving 11951.\n",
      "Pruned 12722 variants from chromosome 10, leaving 13383.\n",
      "Pruned 13053 variants from chromosome 11, leaving 12666.\n",
      "Pruned 11654 variants from chromosome 12, leaving 12500.\n",
      "Pruned 8429 variants from chromosome 13, leaving 9609.\n",
      "Pruned 8072 variants from chromosome 14, leaving 8791.\n",
      "Pruned 7978 variants from chromosome 15, leaving 8470.\n",
      "Pruned 8808 variants from chromosome 16, leaving 9500.\n",
      "Pruned 8032 variants from chromosome 17, leaving 8724.\n",
      "Pruned 7204 variants from chromosome 18, leaving 8560.\n",
      "Pruned 7014 variants from chromosome 19, leaving 6726.\n",
      "Pruned 6341 variants from chromosome 20, leaving 7508.\n",
      "Pruned 3629 variants from chromosome 21, leaving 4280.\n",
      "Pruned 4085 variants from chromosome 22, leaving 4323.\n",
      "Pruned 16235 variants from chromosome 23, leaving 5229.\n",
      "Pruning complete.  272077 of 540534 variants removed.\n",
      "Marker lists written to EUR.QC.prune.in and EUR.QC.prune.out .\n"
     ]
    }
   ],
   "source": [
    "plink \\\n",
    "    --bfile EUR \\\n",
    "    --keep EUR.QC.fam \\\n",
    "    --extract EUR.QC.snplist \\\n",
    "    --indep-pairwise 200 50 0.25 \\\n",
    "    --out EUR.QC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027a789c-cd4d-4449-967e-9f25225face5",
   "metadata": {},
   "source": [
    "This will generate two files 1) EUR.QC.prune.in and 2) EUR.QC.prune.out. All SNPs within EUR.QC.prune.in have a pairwise r2<0.25.\n",
    "\n",
    "これにより2つのファイル1) EUR.QC.prune.inと2) EUR.QC.prune.outが生成される。EUR.QC.prune.in内のSNPはすべてペアワイズr2<0.25である。\n",
    "\n",
    "Heterozygosity rates can then be computed using plink:\n",
    "\n",
    "ヘテロ接合率はplinkを使って計算できる："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b55db1bb-271e-4b34-ba8f-e32875602186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLINK v1.90b7 64-bit (16 Jan 2023)             www.cog-genomics.org/plink/1.9/\n",
      "(C) 2005-2023 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to EUR.QC.log.\n",
      "Options in effect:\n",
      "  --bfile EUR\n",
      "  --extract EUR.QC.prune.in\n",
      "  --het\n",
      "  --keep EUR.QC.fam\n",
      "  --out EUR.QC\n",
      "\n",
      "257564 MB RAM detected; reserving 128782 MB for main workspace.\n",
      "551892 variants loaded from .bim file.\n",
      "503 people (240 males, 263 females) loaded from .fam.\n",
      "--extract: 268457 variants remaining.\n",
      "--keep: 489 people remaining.\n",
      "Using 1 thread (no multithreaded calculations invoked).\n",
      "Before main variant filters, 489 founders and 0 nonfounders present.\n",
      "Calculating allele frequencies... 10111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989 done.\n",
      "Warning: 558 het. haploid genotypes present (see EUR.QC.hh ); many commands\n",
      "treat these as missing.\n",
      "Total genotyping rate in remaining samples is 0.999958.\n",
      "268457 variants and 489 people pass filters and QC.\n",
      "Note: No phenotypes present.\n",
      "--het: 263228 variants scanned, report written to EUR.QC.het .\n"
     ]
    }
   ],
   "source": [
    "plink \\\n",
    "    --bfile EUR \\\n",
    "    --extract EUR.QC.prune.in \\\n",
    "    --keep EUR.QC.fam \\\n",
    "    --het \\\n",
    "    --out EUR.QC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ec24f2-c9fd-4a91-85ca-790b72082ff3",
   "metadata": {},
   "source": [
    "This will generate the EUR.QC.het file, which contains F coefficient estimates for assessing heterozygosity. We will remove individuals with F coefficients that are more than 3 standard deviation (SD) units from the mean, which can be performed using the following R command (assuming that you have R downloaded, then you can open an R session by typing R in your terminal):\n",
    "\n",
    "これはヘテロ接合性を評価するためのF係数推定値を含むEUR.QC.hetファイルを生成する。平均から3標準偏差(SD)単位以上のF係数を持つ個体を削除します。これは、以下のRコマンドで実行できます（Rがダウンロードされていることを仮定して、ターミナルでRとタイプしてRセッションを開くことができます）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7012b2b1-10b2-44a6-b2cd-bb48ea2be315",
   "metadata": {},
   "outputs": [],
   "source": [
    "echo 'dat <- read.table(\"EUR.QC.het\", header=T) # Read in the EUR.het file, specify it has header' > het.R\n",
    "echo 'm <- mean(dat$F) # Calculate the mean' >> het.R\n",
    "echo 's <- sd(dat$F) # Calculate the SD' >> het.R\n",
    "echo 'valid <- subset(dat, F <= m+3*s & F >= m-3*s) # Get any samples with F coefficient within 3 SD of the population mean' >> het.R\n",
    "echo 'write.table(valid[,c(1,2)], \"EUR.valid.sample\", quote=F, row.names=F) # print FID and IID for valid samples' >> het.R\n",
    "\n",
    "Rscript --no-save het.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "66a21eba-45e9-4122-b1bd-0f7b1c214968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EUR.bed  EUR.height  EUR.QC.irem       EUR.QC.snplist      \u001b[0m\u001b[01;31mHeight.gz\u001b[0m\n",
      "EUR.bim  EUR.QC.fam  EUR.QC.log        EUR.valid.sample    \u001b[01;31mHeight.nodup.gz\u001b[0m\n",
      "EUR.cov  EUR.QC.het  EUR.QC.prune.in   \u001b[01;31mEUR.zip\u001b[0m             \u001b[01;31mHeight.QC.gz\u001b[0m\n",
      "EUR.fam  EUR.QC.hh   EUR.QC.prune.out  \u001b[01;31mHeight.gwas.txt.gz\u001b[0m  het.R\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd345c1c-18eb-4c72-8eab-17f28cd0163f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID IID\n",
      "HG00096 HG00096\n",
      "HG00097 HG00097\n",
      "HG00099 HG00099\n",
      "HG00101 HG00101\n",
      "HG00102 HG00102\n",
      "HG00103 HG00103\n",
      "HG00105 HG00105\n",
      "HG00107 HG00107\n",
      "HG00108 HG00108\n"
     ]
    }
   ],
   "source": [
    "head EUR.valid.sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "29cb5af1-f33c-4868-8b81-b8231a2f14c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 488  976 7800 EUR.valid.sample\n",
      "  490  2940 35280 EUR.QC.het\n"
     ]
    }
   ],
   "source": [
    "wc EUR.valid.sample\n",
    "wc EUR.QC.het"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d605c68-6a37-44d8-b903-50237ee7a5b1",
   "metadata": {},
   "source": [
    "#### Ambiguous SNPs\n",
    "These were removed during the base data QC.\n",
    "\n",
    "これらはベースデータのQCで削除された。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f074d2ff-40e7-4447-8798-449ece2f5b20",
   "metadata": {},
   "source": [
    "**【重要】**\n",
    "\n",
    "**ここまでのファイルをhmiwa-lab直下でやってしまったが、大きなデータはhmiwa1の方へ移しておかねばならなかった**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06a93cdb-675d-471d-9431-6f511f9e6554",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/hmiwa/hmiwa-lab/d_20231023/03_231113_TutorialPRS\n",
    "mkdir -p ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS\n",
    "mv data ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbc9c0ce-0d63-40b3-97f9-575b058cd04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hmiwa-lab\n",
      "PRSTutorial1103.ipynb\n",
      "hmiwa1\n",
      "EUR.bed  EUR.height  EUR.QC.irem       EUR.QC.snplist      \u001b[0m\u001b[01;31mHeight.gz\u001b[0m\n",
      "EUR.bim  EUR.QC.fam  EUR.QC.log        EUR.valid.sample    \u001b[01;31mHeight.nodup.gz\u001b[0m\n",
      "EUR.cov  EUR.QC.het  EUR.QC.prune.in   \u001b[01;31mEUR.zip\u001b[0m             \u001b[01;31mHeight.QC.gz\u001b[0m\n",
      "EUR.fam  EUR.QC.hh   EUR.QC.prune.out  \u001b[01;31mHeight.gwas.txt.gz\u001b[0m  het.R\n"
     ]
    }
   ],
   "source": [
    "echo \"hmiwa-lab\"\n",
    "ls ~/hmiwa/hmiwa-lab/d_20231023/03_231113_TutorialPRS\n",
    "echo \"hmiwa1\"\n",
    "ls ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adb893b-828b-46fa-9264-58b83bf4a807",
   "metadata": {},
   "source": [
    "#### Mismatching SNPs\n",
    "SNPs that have mismatching alleles reported in the base and target data may be resolvable by strand-flipping the alleles to their complementary alleles in e.g. the target data, such as for a SNP with A/C in the base data and G/T in the target. This can be achieved with the following steps:\n",
    "\n",
    "ベースデータとターゲットデータで報告されたアレルが不一致のSNPは、例えば、ベースデータでA/C、ターゲットデータでG/TのSNPのように、アレルがターゲットデータで相補的なアレルにストランドフリップすることで解決できる場合がある。これは以下のステップで達成できる：\n",
    "\n",
    ">Most PRS software will perform strand-flipping automatically, thus this step is usually not required.\n",
    ">\n",
    ">ほとんどのPRSソフトウェアは自動的にストランドフリップを行うので、通常このステップは必要ない。\n",
    "\n",
    "##### 1. Load the bim file, the summary statistic and the QC SNP list into R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f331f94-5535-4dfd-b87b-d7c8fdf7c317",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data\n",
    "#1-4は連続して実行すること\n",
    "cat <<EOL > ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data/mismatchSNP.R\n",
    "# Read in bim file\n",
    "bim <- read.table(\"EUR.bim\")\n",
    "colnames(bim) <- c(\"CHR\", \"SNP\", \"CM\", \"BP\", \"B.A1\", \"B.A2\")\n",
    "# Read in QCed SNPs\n",
    "qc <- read.table(\"EUR.QC.snplist\", header = F, stringsAsFactors = F)\n",
    "# Read in the GWAS data\n",
    "height <-\n",
    "    read.table(gzfile(\"Height.QC.gz\"),\n",
    "            header = T,\n",
    "            stringsAsFactors = F, \n",
    "            sep=\"\\t\")\n",
    "# Change all alleles to upper case for easy comparison\n",
    "height\\$A1 <- toupper(height\\$A1)\n",
    "height\\$A2 <- toupper(height\\$A2)\n",
    "bim\\$B.A1 <- toupper(bim\\$B.A1)\n",
    "bim\\$B.A2 <- toupper(bim\\$B.A2)\n",
    "EOL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7d88fa-526c-42a9-a45c-43f6283948ea",
   "metadata": {},
   "source": [
    "##### 2. Identify SNPs that require strand flipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94ec1506-b954-40d8-a8e2-373a403c0011",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat <<EOL >> ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data/mismatchSNP.R\n",
    "# Merge summary statistic with target\n",
    "info <- merge(bim, height, by = c(\"SNP\", \"CHR\", \"BP\"))\n",
    "# Filter QCed SNPs\n",
    "info <- info[info\\$SNP %in% qc\\$V1,]\n",
    "# Function for finding the complementary allele\n",
    "complement <- function(x) {\n",
    "    switch (\n",
    "        x,\n",
    "        \"A\" = \"T\",\n",
    "        \"C\" = \"G\",\n",
    "        \"T\" = \"A\",\n",
    "        \"G\" = \"C\",\n",
    "        return(NA)\n",
    "    )\n",
    "}\n",
    "# Get SNPs that have the same alleles across base and target\n",
    "info.match <- subset(info, A1 == B.A1 & A2 == B.A2)\n",
    "# Identify SNPs that are complementary between base and target\n",
    "info\\$C.A1 <- sapply(info\\$B.A1, complement)\n",
    "info\\$C.A2 <- sapply(info\\$B.A2, complement)\n",
    "info.complement <- subset(info, A1 == C.A1 & A2 == C.A2)\n",
    "# Update the complementary alleles in the bim file\n",
    "# This allow us to match the allele in subsequent analysis\n",
    "complement.snps <- bim\\$SNP %in% info.complement\\$SNP\n",
    "bim[complement.snps,]\\$B.A1 <-\n",
    "    sapply(bim[complement.snps,]\\$B.A1, complement)\n",
    "bim[complement.snps,]\\$B.A2 <-\n",
    "    sapply(bim[complement.snps,]\\$B.A2, complement)\n",
    "EOL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61357c56-1820-4f14-9b06-3376441dfeea",
   "metadata": {},
   "source": [
    "##### 3. Identify SNPs that require recoding in the target (to ensure the coding allele in the target data is the effective allele in the base summary statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c026f59-dad9-4d7f-9660-53aef2e720e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat <<EOL >> ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data/mismatchSNP.R\n",
    "# identify SNPs that need recoding\n",
    "info.recode <- subset(info, A1 == B.A2 & A2 == B.A1)\n",
    "# Update the recode SNPs\n",
    "recode.snps <- bim\\$SNP %in% info.recode\\$SNP\n",
    "tmp <- bim[recode.snps,]\\$B.A1\n",
    "bim[recode.snps,]\\$B.A1 <- bim[recode.snps,]\\$B.A2\n",
    "bim[recode.snps,]\\$B.A2 <- tmp\n",
    "\n",
    "# identify SNPs that need recoding & complement\n",
    "info.crecode <- subset(info, A1 == C.A2 & A2 == C.A1)\n",
    "# Update the recode + strand flip SNPs\n",
    "com.snps <- bim\\$SNP %in% info.crecode\\$SNP\n",
    "tmp <- bim[com.snps,]\\$B.A1\n",
    "bim[com.snps,]\\$B.A1 <- as.character(sapply(bim[com.snps,]\\$B.A2, complement))\n",
    "bim[com.snps,]\\$B.A2 <- as.character(sapply(tmp, complement))\n",
    "\n",
    "# Output updated bim file\n",
    "write.table(\n",
    "    bim[,c(\"SNP\", \"B.A1\")],\n",
    "    \"EUR.a1\",\n",
    "    quote = F,\n",
    "    row.names = F,\n",
    "    col.names = F,\n",
    "    sep=\"\\t\"\n",
    ")\n",
    "EOL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d2f8ca-54f2-4ed4-8402-8bbd3ef4a201",
   "metadata": {},
   "source": [
    "##### 4. Identify SNPs that have different allele in base and target (usually due to difference in genome build or Indel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b28472ba-bf72-4ebb-b474-1e5a4caf5ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat <<EOL >> ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data/mismatchSNP.R\n",
    "mismatch <-\n",
    "    bim\\$SNP[!(bim\\$SNP %in% info.match\\$SNP |\n",
    "                bim\\$SNP %in% info.complement\\$SNP | \n",
    "                bim\\$SNP %in% info.recode\\$SNP |\n",
    "                bim\\$SNP %in% info.crecode\\$SNP)]\n",
    "write.table(\n",
    "    mismatch,\n",
    "    \"EUR.mismatch\",\n",
    "    quote = F,\n",
    "    row.names = F,\n",
    "    col.names = F\n",
    ")\n",
    "EOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a093b82-c9f4-45b9-90c8-32a1d29c0fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Read in bim file\n",
      "bim <- read.table(\"EUR.bim\")\n",
      "colnames(bim) <- c(\"CHR\", \"SNP\", \"CM\", \"BP\", \"B.A1\", \"B.A2\")\n",
      "# Read in QCed SNPs\n",
      "qc <- read.table(\"EUR.QC.snplist\", header = F, stringsAsFactors = F)\n",
      "# Read in the GWAS data\n",
      "height <-\n",
      "    read.table(gzfile(\"Height.QC.gz\"),\n",
      "            header = T,\n",
      "            stringsAsFactors = F, \n",
      "            sep=\"\\t\")\n",
      "# Change all alleles to upper case for easy comparison\n",
      "height$A1 <- toupper(height$A1)\n",
      "height$A2 <- toupper(height$A2)\n",
      "bim$B.A1 <- toupper(bim$B.A1)\n",
      "bim$B.A2 <- toupper(bim$B.A2)\n",
      "# Merge summary statistic with target\n",
      "info <- merge(bim, height, by = c(\"SNP\", \"CHR\", \"BP\"))\n",
      "# Filter QCed SNPs\n",
      "info <- info[info$SNP %in% qc$V1,]\n",
      "# Function for finding the complementary allele\n",
      "complement <- function(x) {\n",
      "    switch (\n",
      "        x,\n",
      "        \"A\" = \"T\",\n",
      "        \"C\" = \"G\",\n",
      "        \"T\" = \"A\",\n",
      "        \"G\" = \"C\",\n",
      "        return(NA)\n",
      "    )\n",
      "}\n",
      "# Get SNPs that have the same alleles across base and target\n",
      "info.match <- subset(info, A1 == B.A1 & A2 == B.A2)\n",
      "# Identify SNPs that are complementary between base and target\n",
      "info$C.A1 <- sapply(info$B.A1, complement)\n",
      "info$C.A2 <- sapply(info$B.A2, complement)\n",
      "info.complement <- subset(info, A1 == C.A1 & A2 == C.A2)\n",
      "# Update the complementary alleles in the bim file\n",
      "# This allow us to match the allele in subsequent analysis\n",
      "complement.snps <- bim$SNP %in% info.complement$SNP\n",
      "bim[complement.snps,]$B.A1 <-\n",
      "    sapply(bim[complement.snps,]$B.A1, complement)\n",
      "bim[complement.snps,]$B.A2 <-\n",
      "    sapply(bim[complement.snps,]$B.A2, complement)\n",
      "# identify SNPs that need recoding\n",
      "info.recode <- subset(info, A1 == B.A2 & A2 == B.A1)\n",
      "# Update the recode SNPs\n",
      "recode.snps <- bim$SNP %in% info.recode$SNP\n",
      "tmp <- bim[recode.snps,]$B.A1\n",
      "bim[recode.snps,]$B.A1 <- bim[recode.snps,]$B.A2\n",
      "bim[recode.snps,]$B.A2 <- tmp\n",
      "\n",
      "# identify SNPs that need recoding & complement\n",
      "info.crecode <- subset(info, A1 == C.A2 & A2 == C.A1)\n",
      "# Update the recode + strand flip SNPs\n",
      "com.snps <- bim$SNP %in% info.crecode$SNP\n",
      "tmp <- bim[com.snps,]$B.A1\n",
      "bim[com.snps,]$B.A1 <- as.character(sapply(bim[com.snps,]$B.A2, complement))\n",
      "bim[com.snps,]$B.A2 <- as.character(sapply(tmp, complement))\n",
      "\n",
      "# Output updated bim file\n",
      "write.table(\n",
      "    bim[,c(\"SNP\", \"B.A1\")],\n",
      "    \"EUR.a1\",\n",
      "    quote = F,\n",
      "    row.names = F,\n",
      "    col.names = F,\n",
      "    sep=\"\\t\"\n",
      ")\n",
      "mismatch <-\n",
      "    bim$SNP[!(bim$SNP %in% info.match$SNP |\n",
      "                bim$SNP %in% info.complement$SNP | \n",
      "                bim$SNP %in% info.recode$SNP |\n",
      "                bim$SNP %in% info.crecode$SNP)]\n",
      "write.table(\n",
      "    mismatch,\n",
      "    \"EUR.mismatch\",\n",
      "    quote = F,\n",
      "    row.names = F,\n",
      "    col.names = F\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cat ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data/mismatchSNP.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb2d6345-e908-4e53-a4e5-be6ccdb20354",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rscript ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data/mismatchSNP.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a52fa7b1-4640-4088-a244-067bbf25536e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EUR.a1   EUR.height    EUR.QC.irem       EUR.valid.sample    \u001b[0m\u001b[01;31mHeight.QC.gz\u001b[0m\n",
      "EUR.bed  EUR.mismatch  EUR.QC.log        \u001b[01;31mEUR.zip\u001b[0m             het.R\n",
      "EUR.bim  EUR.QC.fam    EUR.QC.prune.in   \u001b[01;31mHeight.gwas.txt.gz\u001b[0m  mismatchSNP.R\n",
      "EUR.cov  EUR.QC.het    EUR.QC.prune.out  \u001b[01;31mHeight.gz\u001b[0m\n",
      "EUR.fam  EUR.QC.hh     EUR.QC.snplist    \u001b[01;31mHeight.nodup.gz\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ls ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5498c578-d867-4466-a945-fbaf7ea6e9f3",
   "metadata": {},
   "source": [
    "#### Duplicate SNPs\n",
    "Make sure to remove any duplicate SNPs in your target data (these target data were simulated and so include no duplicated SNPs).\n",
    "\n",
    "ターゲットデータ中の重複SNPを必ず削除してください（これらのターゲットデータはシミュレートされたため、重複SNPは含まれていません）。\n",
    "#### Sex chromosomes\n",
    "Sometimes sample mislabelling can occur, which may lead to invalid results. One indication of a mislabelled sample is a difference between reported sex and that indicated by the sex chromosomes. While this may be due to a difference in sex and gender identity, it could also reflect mislabeling of samples or misreporting and, thus, individuals in which there is a mismatch between biological and reported sex are typically removed. A sex check can be performed in PLINK, in which individuals are called as females if their X chromosome homozygosity estimate (F statistic) is < 0.2 and as males if the estimate is > 0.8.\n",
    "\n",
    "時には検体の誤ラベリングが起こり、無効な結果につながることがあります。誤ラベリングされたサンプルの兆候の一つは、報告された性と性染色体が示す性との違いである。これは性別や性自認の違いに起因する場合もありますが、サンプルの誤ラベリングや誤った報告を反映している可能性もあり、そのため、生物学的性別と報告された性別の間に不一致がある個体は通常除外されます。性チェックはPLINKで行うことができ、X染色体のホモ接合性の推定値（F統計量）が0.2未満の個体はメス、0.8以上の個体はオスと呼ばれる。\n",
    "\n",
    "Before performing a sex check, pruning should be performed (see here). A sex check can then easily be conducted using plink\n",
    "\n",
    "性チェックを行う前に、剪定を行うべきである（こちらを参照）。その後、plinkを使って簡単に雌雄チェックを行うことができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "245185f6-38ff-4856-8739-671a6e648cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLINK v1.90b7 64-bit (16 Jan 2023)             www.cog-genomics.org/plink/1.9/\n",
      "(C) 2005-2023 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to EUR.QC.log.\n",
      "Options in effect:\n",
      "  --bfile EUR\n",
      "  --check-sex\n",
      "  --extract EUR.QC.prune.in\n",
      "  --keep EUR.valid.sample\n",
      "  --out EUR.QC\n",
      "\n",
      "257564 MB RAM detected; reserving 128782 MB for main workspace.\n",
      "551892 variants loaded from .bim file.\n",
      "503 people (240 males, 263 females) loaded from .fam.\n",
      "--extract: 268457 variants remaining.\n",
      "--keep: 487 people remaining.\n",
      "Using 1 thread (no multithreaded calculations invoked).\n",
      "Before main variant filters, 487 founders and 0 nonfounders present.\n",
      "Calculating allele frequencies... 10111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989 done.\n",
      "Warning: 558 het. haploid genotypes present (see EUR.QC.hh ); many commands\n",
      "treat these as missing.\n",
      "Total genotyping rate in remaining samples is 0.999958.\n",
      "268457 variants and 487 people pass filters and QC.\n",
      "Note: No phenotypes present.\n",
      "--check-sex: 5229 Xchr and 0 Ychr variant(s) scanned, 4 problems detected.\n",
      "Report written to EUR.QC.sexcheck .\n"
     ]
    }
   ],
   "source": [
    "plink \\\n",
    "    --bfile EUR \\\n",
    "    --extract EUR.QC.prune.in \\\n",
    "    --keep EUR.valid.sample \\\n",
    "    --check-sex \\\n",
    "    --out EUR.QC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c1383a-fcf0-4d12-a775-f413957331fc",
   "metadata": {},
   "source": [
    "This will generate a file called EUR.QC.sexcheck containing the F-statistics for each individual. Individuals are typically called as being biologically male if the F-statistic is > 0.8 and biologically female if F < 0.2.\n",
    "\n",
    "これにより、各個体のF統計量を含むEUR.QC.sexcheckというファイルが生成される。F統計量が0.8以上の個体は生物学的に男性であり、0.2未満の個体は生物学的に女性であると通常呼ばれます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c830d11d-b59b-4f52-873d-8673033dae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat <<EOL >> ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data/sexcheck.R\n",
    "# Read in file\n",
    "valid <- read.table(\"EUR.valid.sample\", header=T)\n",
    "dat <- read.table(\"EUR.QC.sexcheck\", header=T)\n",
    "valid <- subset(dat, STATUS==\"OK\" & FID %in% valid\\$FID)\n",
    "write.table(valid[,c(\"FID\", \"IID\")], \"EUR.QC.valid\", row.names=F, col.names=F, sep=\"\\t\", quote=F) \n",
    "EOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e64aef4a-d297-44be-b828-603b622384c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Read in file\n",
      "valid <- read.table(\"EUR.valid.sample\", header=T)\n",
      "dat <- read.table(\"EUR.QC.sexcheck\", header=T)\n",
      "valid <- subset(dat, STATUS==\"OK\" & FID %in% valid$FID)\n",
      "write.table(valid[,c(\"FID\", \"IID\")], \"EUR.QC.valid\", row.names=F, col.names=F, sep=\"\\t\", quote=F) \n"
     ]
    }
   ],
   "source": [
    "cat ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data/sexcheck.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11b1ca83-cb29-4ae8-8996-60b46c446882",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rscript ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data/sexcheck.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a905c2e5-44f5-4ba4-b4eb-9187979022b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EUR.a1      EUR.mismatch  EUR.QC.prune.in   \u001b[0m\u001b[01;31mEUR.zip\u001b[0m             mismatchSNP.R\n",
      "EUR.bed     EUR.QC.fam    EUR.QC.prune.out  \u001b[01;31mHeight.gwas.txt.gz\u001b[0m  sexcheck.R\n",
      "EUR.bim     EUR.QC.het    EUR.QC.sexcheck   \u001b[01;31mHeight.gz\u001b[0m\n",
      "EUR.cov     EUR.QC.hh     EUR.QC.snplist    \u001b[01;31mHeight.nodup.gz\u001b[0m\n",
      "EUR.fam     EUR.QC.irem   EUR.QC.valid      \u001b[01;31mHeight.QC.gz\u001b[0m\n",
      "EUR.height  EUR.QC.log    EUR.valid.sample  het.R\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c6c6fba-0a74-4bec-8eca-3e8785333dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HG00096\tHG00096\n",
      "HG00097\tHG00097\n",
      "HG00099\tHG00099\n",
      "HG00101\tHG00101\n",
      "HG00102\tHG00102\n",
      "HG00103\tHG00103\n",
      "HG00105\tHG00105\n",
      "HG00107\tHG00107\n",
      "HG00108\tHG00108\n",
      "HG00109\tHG00109\n"
     ]
    }
   ],
   "source": [
    "head EUR.QC.valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7d83605-1e1e-4e73-9e90-63f6477acea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      FID       IID       PEDSEX       SNPSEX       STATUS            F\n",
      "  HG00096   HG00096            1            1           OK            1\n",
      "  HG00097   HG00097            2            2           OK       -0.217\n",
      "  HG00099   HG00099            2            2           OK      -0.1848\n",
      "  HG00101   HG00101            1            1           OK            1\n",
      "  HG00102   HG00102            2            2           OK      -0.3558\n",
      "  HG00103   HG00103            1            1           OK            1\n",
      "  HG00105   HG00105            1            1           OK            1\n",
      "  HG00107   HG00107            1            1           OK            1\n",
      "  HG00108   HG00108            1            1           OK            1\n"
     ]
    }
   ],
   "source": [
    "head EUR.QC.sexcheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94c38189-9610-4f51-83ab-9294ef8ec799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 483  966 7728 EUR.QC.valid\n",
      "  488  2928 35136 EUR.QC.sexcheck\n"
     ]
    }
   ],
   "source": [
    "wc EUR.QC.valid\n",
    "wc EUR.QC.sexcheck"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c798cce8-4f11-4717-a2ba-760b3e84526c",
   "metadata": {},
   "source": [
    "#### Sample overlap\n",
    "Since the target data were simulated there are no overlapping samples between the base and target data here (see the relevant section of the paper for discussion of the importance of avoiding sample overlap).\n",
    "\n",
    "ターゲットデータはシミュレートされたものであるため、ベースデータとターゲットデータの間に重複するサンプルはない（サンプルの重複を避けることの重要性については、論文の関連セクションを参照）。\n",
    "#### Relatedness\n",
    "Closely related individuals in the target data may lead to overfitted results, limiting the generalisability of the results.\r\n",
    "対象データ中の近縁の個体は、過剰適合を引き起こし、結果の一般性を制限する可能性がある。\n",
    "\n",
    "\r\n",
    "Before calculating the relatedness, pruning should be performed (see here). Individuals that have a first or second degree relative in the sample\n",
    "\r",
    "π\r\n",
    ">\r",
    "0.125\r\n",
    ") can be removed with the following co\n",
    "近縁度を計算する前に、プルーニングを行うべきである（こちらを参照）。サンプル中に1度または2度の近親者がいる個体（π>0.125）は、以下のコマンドで削除できます：ta file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b54a7544-081d-4303-bd59-a3a20576eca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLINK v1.90b7 64-bit (16 Jan 2023)             www.cog-genomics.org/plink/1.9/\n",
      "(C) 2005-2023 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to EUR.QC.log.\n",
      "Options in effect:\n",
      "  --bfile EUR\n",
      "  --extract EUR.QC.prune.in\n",
      "  --keep EUR.QC.valid\n",
      "  --out EUR.QC\n",
      "  --rel-cutoff 0.125\n",
      "\n",
      "257564 MB RAM detected; reserving 128782 MB for main workspace.\n",
      "551892 variants loaded from .bim file.\n",
      "503 people (240 males, 263 females) loaded from .fam.\n",
      "--extract: 268457 variants remaining.\n",
      "--keep: 483 people remaining.\n",
      "Using up to 63 threads (change this with --threads).\n",
      "Before main variant filters, 483 founders and 0 nonfounders present.\n",
      "Calculating allele frequencies... 10111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989 done.\n",
      "Total genotyping rate in remaining samples is 0.999957.\n",
      "268457 variants and 483 people pass filters and QC (before --rel-cutoff).\n",
      "Note: No phenotypes present.\n",
      "Excluding 5229 variants on non-autosomes from relationship matrix calc.\n",
      "Relationship matrix calculation complete.\n",
      "0 people excluded by --rel-cutoff.\n",
      "Remaining sample IDs written to EUR.QC.rel.id .\n"
     ]
    }
   ],
   "source": [
    "plink \\\n",
    "    --bfile EUR \\\n",
    "    --extract EUR.QC.prune.in \\\n",
    "    --keep EUR.QC.valid \\\n",
    "    --rel-cutoff 0.125 \\\n",
    "    --out EUR.QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "475b6a58-e468-48a2-928a-aa37e6242768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EUR.a1      EUR.mismatch  EUR.QC.prune.in   EUR.valid.sample    het.R\n",
      "EUR.bed     EUR.QC.fam    EUR.QC.prune.out  \u001b[0m\u001b[01;31mEUR.zip\u001b[0m             mismatchSNP.R\n",
      "EUR.bim     EUR.QC.het    EUR.QC.rel.id     \u001b[01;31mHeight.gwas.txt.gz\u001b[0m  sexcheck.R\n",
      "EUR.cov     EUR.QC.hh     EUR.QC.sexcheck   \u001b[01;31mHeight.gz\u001b[0m\n",
      "EUR.fam     EUR.QC.irem   EUR.QC.snplist    \u001b[01;31mHeight.nodup.gz\u001b[0m\n",
      "EUR.height  EUR.QC.log    EUR.QC.valid      \u001b[01;31mHeight.QC.gz\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6dbfe8c1-c116-4412-9945-e74619b95cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HG00096\tHG00096\n",
      "HG00097\tHG00097\n",
      "HG00099\tHG00099\n",
      "HG00101\tHG00101\n",
      "HG00102\tHG00102\n",
      "HG00103\tHG00103\n",
      "HG00105\tHG00105\n",
      "HG00107\tHG00107\n",
      "HG00108\tHG00108\n",
      "HG00109\tHG00109\n",
      " 483  966 7728 EUR.QC.rel.id\n"
     ]
    }
   ],
   "source": [
    "head EUR.QC.rel.id\n",
    "wc EUR.QC.rel.id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a21efa-cd00-44cb-bd09-72d5ea254fce",
   "metadata": {},
   "source": [
    ">A greedy algorithm is used to remove closely related individuals in a way that optimizes the size of the sample retained. However, the algorithm is dependent on the random seed used, which can generate different results. Therefore, to reproduce the same result, you will need to specify the same random seed.\n",
    ">\r",
    ">貪欲なアルゴリズムは、保持されるサンプルのサイズを最適化する方法で、近縁の個体を除去するために使用される。しかし、このアルゴリズムは使用するランダムシードに依存し、異なる結果を生成することがあります。したがって、同じ結果を再現するには、同じランダム・シードを指定する必要があります。\n",
    "\n",
    ">PLINK's algorithm for removing related individuals does not account for the phenotype under study. To minimize the removal of cases of a disease, the following algorithm can be used instead: GreedyRelated.\n",
    ">\n",
    ">近縁個体を除去するPLINKのアルゴリズムは、調査対象の表現型を考慮していません。病気のケースの除去を最小にするために、代わりに以下のアルゴリズムを使用できます： GreedyRelated.le"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0e7ef3-d80e-4fb2-aa8e-139720be1f13",
   "metadata": {},
   "source": [
    "### Generate final QC'ed target data file\n",
    "After performing the full analysis, you can generate a QC'ed data set with the following command:\n",
    "\n",
    "完全な分析を行った後、以下のコマンドでQCされたデータセットを生成することができる："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c7d3a963-925e-43e3-b101-9f670094917d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLINK v1.90b7 64-bit (16 Jan 2023)             www.cog-genomics.org/plink/1.9/\n",
      "(C) 2005-2023 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to EUR.QC.log.\n",
      "Options in effect:\n",
      "  --a1-allele EUR.a1\n",
      "  --bfile EUR\n",
      "  --exclude EUR.mismatch\n",
      "  --extract EUR.QC.snplist\n",
      "  --keep EUR.QC.rel.id\n",
      "  --make-bed\n",
      "  --out EUR.QC\n",
      "\n",
      "257564 MB RAM detected; reserving 128782 MB for main workspace.\n",
      "551892 variants loaded from .bim file.\n",
      "503 people (240 males, 263 females) loaded from .fam.\n",
      "--extract: 540534 variants remaining.\n",
      "--exclude: 489805 variants remaining.\n",
      "--keep: 483 people remaining.\n",
      "Using 1 thread (no multithreaded calculations invoked).\n",
      "Before main variant filters, 483 founders and 0 nonfounders present.\n",
      "Calculating allele frequencies... 10111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989 done.\n",
      "Total genotyping rate in remaining samples is exactly 1.\n",
      "--a1-allele: 489805 assignments made.\n",
      "489805 variants and 483 people pass filters and QC.\n",
      "Note: No phenotypes present.\n",
      "--make-bed to EUR.QC.bed + EUR.QC.bim + EUR.QC.fam ... 101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899done.\n"
     ]
    }
   ],
   "source": [
    "plink \\\n",
    "    --bfile EUR \\\n",
    "    --make-bed \\\n",
    "    --keep EUR.QC.rel.id \\\n",
    "    --out EUR.QC \\\n",
    "    --extract EUR.QC.snplist \\\n",
    "    --exclude EUR.mismatch \\\n",
    "    --a1-allele EUR.a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6997862b-bc93-4b37-8c38-7440ee997f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EUR.a1      EUR.mismatch  EUR.QC.irem       EUR.QC.snplist      \u001b[0m\u001b[01;31mHeight.nodup.gz\u001b[0m\n",
      "EUR.bed     EUR.QC.bed    EUR.QC.log        EUR.QC.valid        \u001b[01;31mHeight.QC.gz\u001b[0m\n",
      "EUR.bim     EUR.QC.bim    EUR.QC.prune.in   EUR.valid.sample    het.R\n",
      "EUR.cov     EUR.QC.fam    EUR.QC.prune.out  \u001b[01;31mEUR.zip\u001b[0m             mismatchSNP.R\n",
      "EUR.fam     EUR.QC.het    EUR.QC.rel.id     \u001b[01;31mHeight.gwas.txt.gz\u001b[0m  sexcheck.R\n",
      "EUR.height  EUR.QC.hh     EUR.QC.sexcheck   \u001b[01;31mHeight.gz\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ea6a4c-7397-4f65-ae16-945e2242b6fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
