{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6f6cc23-d11a-41a2-a717-efd9f4ecc429",
   "metadata": {},
   "source": [
    "# Basic Tutorial for Polygenic Risk Score Analysis\n",
    "\n",
    "https://choishingwan.github.io/PRS-Tutorial/\n",
    "\n",
    "今回はこれにしたがって動かしてみます"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a4b1d0-87be-4f43-b12a-d716ef8b84ed",
   "metadata": {},
   "source": [
    "## 1. QC of Base Data\n",
    "\n",
    "### Obtaining the base data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49458777-bf33-43c8-9f13-3763f95f5ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-11-13 01:50:18--  https://drive.google.com/u/0/uc?id=1RWjk49QNZj9zvJHc9X_wyZ51fdy6xQjv&export=download\n",
      "Resolving drive.google.com (drive.google.com)... 172.217.26.238, 2404:6800:4004:801::200e\n",
      "Connecting to drive.google.com (drive.google.com)|172.217.26.238|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://drive.google.com/uc?id=1RWjk49QNZj9zvJHc9X_wyZ51fdy6xQjv&export=download [following]\n",
      "--2023-11-13 01:50:18--  https://drive.google.com/uc?id=1RWjk49QNZj9zvJHc9X_wyZ51fdy6xQjv&export=download\n",
      "Reusing existing connection to drive.google.com:443.\n",
      "HTTP request sent, awaiting response... 303 See Other\n",
      "Location: https://doc-08-bo-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/i0q63k8tmcl049rvs9m96mh6os68hsoe/1699807800000/00063656433649606985/*/1RWjk49QNZj9zvJHc9X_wyZ51fdy6xQjv?e=download&uuid=e2ae40ef-b410-41e3-ae97-aa5399397f4c [following]\n",
      "Warning: wildcards not supported in HTTP.\n",
      "--2023-11-13 01:50:19--  https://doc-08-bo-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/i0q63k8tmcl049rvs9m96mh6os68hsoe/1699807800000/00063656433649606985/*/1RWjk49QNZj9zvJHc9X_wyZ51fdy6xQjv?e=download&uuid=e2ae40ef-b410-41e3-ae97-aa5399397f4c\n",
      "Resolving doc-08-bo-docs.googleusercontent.com (doc-08-bo-docs.googleusercontent.com)... 172.217.31.161, 2404:6800:4004:80c::2001\n",
      "Connecting to doc-08-bo-docs.googleusercontent.com (doc-08-bo-docs.googleusercontent.com)|172.217.31.161|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 22609185 (22M) [application/x-gzip]\n",
      "Saving to: ‘Height.gwas.txt.gz’\n",
      "\n",
      "Height.gwas.txt.gz  100%[===================>]  21.56M  37.5MB/s    in 0.6s    \n",
      "\n",
      "2023-11-13 01:50:21 (37.5 MB/s) - ‘Height.gwas.txt.gz’ saved [22609185/22609185]\n",
      "\n",
      "\u001b[0m\u001b[01;31mHeight.gwas.txt.gz\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#データのダウンロード\n",
    "cd ~/hmiwa/hmiwa-lab/d_20231023/03_231113_TutorialPRS\n",
    "mkdir -p data\n",
    "cd data\n",
    "wget \"https://drive.google.com/u/0/uc?id=1RWjk49QNZj9zvJHc9X_wyZ51fdy6xQjv&export=download\" -O Height.gwas.txt.gz\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d7b37b-3e98-436f-a643-90a8172611e7",
   "metadata": {},
   "source": [
    "注）google ドライブからwgetで取得するヒントはこちら\n",
    "\n",
    "https://qiita.com/namakemono/items/c963e75e0af3f7eed732"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c225c8-e4ea-4976-b75c-fbb47a3d38a9",
   "metadata": {},
   "source": [
    "### Reading the base data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a68c4bfd-beb3-41b5-bbc5-fb634ee0e9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHR\tBP\tSNP\tA1\tA2\tN\tSE\tP\tOR\tINFO\tMAF\n",
      "1\t756604\trs3131962\tA\tG\t388028\t0.00301666\t0.483171\t0.997886915712657\t0.890557941364774\t0.369389592764921\n",
      "1\t768448\trs12562034\tA\tG\t388028\t0.00329472\t0.834808\t1.00068731609353\t0.895893511351165\t0.336845754096289\n",
      "1\t779322\trs4040617\tG\tA\t388028\t0.00303344\t0.42897\t0.997603556067569\t0.897508290615237\t0.377368010940814\n",
      "1\t801536\trs79373928\tG\tT\t388028\t0.00841324\t0.808999\t1.00203569922793\t0.908962856432993\t0.483212245374095\n",
      "1\t808631\trs11240779\tG\tA\t388028\t0.00242821\t0.590265\t1.00130832511154\t0.893212523690488\t0.450409558999587\n",
      "1\t809876\trs57181708\tG\tA\t388028\t0.00336785\t0.71475\t1.00123165786833\t0.923557624081969\t0.499743932656759\n",
      "1\t835499\trs4422948\tG\tA\t388028\t0.0023758\t0.710884\t0.999119752645202\t0.906437735120596\t0.481016005816168\n",
      "1\t838555\trs4970383\tA\tC\t388028\t0.00235773\t0.150993\t0.996619945289758\t0.907716506801574\t0.327164029672754\n",
      "1\t840753\trs4970382\tC\tT\t388028\t0.00207377\t0.199967\t0.99734567895614\t0.914602590137255\t0.498936220426316\n",
      "\n",
      "gzip: stdout: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "#なかみの確認\n",
    "gunzip -c Height.gwas.txt.gz | head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456cc74c-8186-4f8e-a6b4-0d82211957a9",
   "metadata": {},
   "source": [
    "列の内容について：（サイトから引用）\n",
    "* CHR: The chromosome in which the SNP resides\n",
    "* BP: Chromosomal co-ordinate of the SNP\n",
    "* SNP: SNP ID, usually in the form of rs-ID\n",
    "* A1: The effect allele of the SNP\n",
    "* A2: The non-effect allele of the SNP\n",
    "* N: Number of samples used to obtain the effect size estimate\n",
    "* SE: The standard error (SE) of the effect size esimate\n",
    "* P: The P-value of association between the SNP genotypes and the base phenotype\n",
    "* OR: The effect size estimate of the SNP, if the outcome is binary/case-control. If the outcome is continuous or treated as continuous then this will usually be BETA\n",
    "* INFO: The imputation information score\n",
    "* MAF: The minor allele frequency (MAF) of the SNP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108be9b8-7e80-47a3-b118-52a3ba5309f1",
   "metadata": {},
   "source": [
    "### QC checklist: Base data\n",
    "\n",
    "#### Heritability check\n",
    "\n",
    "We recommend that PRS analyses are performed on base data with a chip-heritability estimate h2snp>0.05. The chip-heritability of a GWAS can be estimated using e.g. LD Score Regression (LDSC). Our height GWAS data are simulated to have a chip-heritability much greater than 0.05 and so we can move on to the next QC step.\n",
    "\n",
    "PRS解析はチップヘリタビリティ推定値h2snp>0.05のベースデータで行うことを推奨する。GWASのチップヘリタビリティーは、例えばLD Score Regression (LDSC)を用いて推定することができる。我々の身長GWASデータは、0.05よりはるかに大きいチップヘリタビリティーを持つようにシミュレートされているので、次のQCステップに進むことができる。\n",
    "\n",
    "#### Effect allele\n",
    "\n",
    "It is important to know which allele is the effect allele and which is the non-effect allele for PRS association results to be in the correct direction.\n",
    "\n",
    "PRSの関連結果を正しい方向に導くためには、どの対立遺伝子が効果対立遺伝子で、どの対立遺伝子が非効果対立遺伝子かを知ることが重要である。\n",
    "\n",
    ">Some GWAS results files do not make clear which allele is the effect allele and which is the non-effect allele. If the incorrect assumption is made in computing the PRS, then the effect of the PRS in the target data will be in the wrong direction.\n",
    ">\n",
    ">GWASの結果ファイルの中には、どの対立遺伝子が効果対立遺伝子で、どの対立遺伝子が非効果対立遺伝子なのかを明確にしていないものがある。PRSを計算する際に間違った仮定がなされると、対象データにおけるPRSの効果は間違った方向になる。\n",
    ">\n",
    ">To avoid misleading conclusions the effect allele from the base (GWAS) data must be known.\n",
    ">\n",
    ">誤解を招く結論を避けるためには、ベース（GWAS）データからの効果対立遺伝子を知っていなければならない。\n",
    "\n",
    "#### File transfer\n",
    "\n",
    "A common problem is that the downloaded base data file can be corrupted during download, which can cause PRS software to crash or to produce errors in results. However, a md5sum hash is generally included in files so that file integrity can be checked. The following command performs this md5sum check:\n",
    "\n",
    "よくある問題は、ダウンロードしたベースデータファイルがダウンロード中に破損し、PRSソフトウェアがクラッシュしたり、結果にエラーが出ることです。しかし、ファイルの完全性をチェックできるように、一般的にファイルにはmd5sumハッシュが含まれています。次のコマンドは、このmd5sumチェックを実行します："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8877ad26-193d-4954-ba79-9b800d606b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2b15fb6a2bbbe7ef49f67959b43b160  Height.gwas.txt.gz\n"
     ]
    }
   ],
   "source": [
    "md5sum Height.gwas.txt.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bedcda-8ff4-4d4b-bf5c-09a8ae2e60aa",
   "metadata": {},
   "source": [
    "if the file is intact, then md5sum generates a string of characters, which in this case should be: a2b15fb6a2bbbe7ef49f67959b43b160. If a different string is generated, then the file is corrupted.\n",
    "\n",
    "ファイルが無傷の場合、md5sumは文字列を生成し、この場合a2b15fb6a2bbbe7ef49f67959b43b160となる。異なる文字列が生成された場合、ファイルは壊れている。\n",
    "\n",
    "#### Genome build\n",
    "\n",
    "The height summary statistic are on the same genome build as the target data that we will be using. You must check that your base and target data are on the same genome build, and if they are not then use a tool such as LiftOver to make the builds consistent across the data sets.\n",
    "\n",
    "高さの要約統計量は、これから使用するターゲットデータと同じゲノムビルドにあります。ベースデータとターゲットデータが同じゲノムビルド上にあることを確認し、もしそうでない場合は、LiftOverのようなツールを使ってデータセット間でビルドを一貫させる必要があります。\n",
    "\n",
    "LiftOver:https://genome.ucsc.edu/cgi-bin/hgLiftOver\n",
    "\n",
    "#### Standard GWAS QC\n",
    "\n",
    "As described in the paper, both the base and target data should be subjected to the standard stringent QC steps performed in GWAS. If the base data have been obtained as summary statistics from a public source, then the typical QC steps that you will be able to perform on them are to filter the SNPs according to INFO score and MAF. SNPs with low minor allele frequency (MAF) or imputation information score (INFO) are more likely to generate false positive results due to their lower statistical power (and higher probability of genotyping errors in the case of low MAF). Therefore, SNPs with low MAF and INFO are typically removed before performing downstream analyses. We recommend removing SNPs with MAF < 1% and INFO < 0.8 (with very large base sample sizes these thresholds could be reduced if sensitivity checks indicate reliable results). These SNP filters can be achieved using the following code:\n",
    "\n",
    "論文に記載されているように、ベースデータとターゲットデータの両方は、GWASで実行される標準的な厳格なQCステップに従うべきである。もしベースデータが公開されているソースから要約統計として取得されたものであれば、それに対して実行できる典型的なQCステップは、INFOスコアとMAFに従ってSNPをフィルタリングすることである。マイナーアレル頻度（MAF）またはインピュテーション情報スコア（INFO）が低いSNPは、統計的検出力が低い（MAFが低い場合はジェノタイピングエラーの確率が高い）ため、偽陽性の結果を生成する可能性が高くなります。したがって、MAFやINFOが低いSNPは、ダウンストリーム解析を行う前に除去するのが一般的である。MAF＜1％、INFO＜0.8のSNPを除去することを推奨する（ベースサンプルサイズが非常に大きい場合、感度のチェックで信頼できる結果が示されれば、これらの閾値を下げることができる）。これらのSNPフィルターは以下のコードで実現できます："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "083b5c6d-1b67-4e60-911f-08de1cd36ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gunzip -c Height.gwas.txt.gz |\\\n",
    "awk 'NR==1 || ($11 > 0.01) && ($10 > 0.8) {print}' |\\\n",
    "gzip  > Height.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f6ce8f8-c9b2-4e7f-95c9-23815d2da369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;31mHeight.gwas.txt.gz\u001b[0m  \u001b[01;31mHeight.gz\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f574e48-eb1b-4a01-9847-35a775e4107c",
   "metadata": {},
   "source": [
    "The bash code above does the following:\n",
    "\n",
    "1. Decompresses and reads the Height.gwas.txt.gz file\n",
    "2. Prints the header line (NR==1)\n",
    "3. Prints any line with MAF above 0.01 (\\$11 because the eleventh column of the file contains the MAF information)\n",
    "4. Prints any line with INFO above 0.8 (\\$10 because the tenth column of the file contains the INFO information)\n",
    "5. Compresses and writes the results to Height.gz\n",
    "\n",
    "#### Mismatching SNPs\n",
    "\n",
    "SNPs that have mismatching alleles reported in the base and target data are either resolvable by \"strand-flipping\" the alleles to their complementary alleles in e.g. the target data, such as for a SNP with A/C in the base data and G/T in the target, or non-resolvable, such as for a SNP with C/G in the base and C/T in the target. Most polygenic score software perform strand-flipping automatically for SNPs that are resolvable, and remove non-resolvable mismatching SNPs.\n",
    "\n",
    "ベースデータとターゲットデータで報告された対立遺伝子が不一致のSNPは、例えばベースデータでA/C、ターゲットデータでG/TのSNPのように、ターゲットデータで対立遺伝子を相補的な対立遺伝子に \"ストランドフリップ \"することによって解決可能か、あるいはベースデータでC/G、ターゲットデータでC/TのSNPのように解決不可能かのいずれかである。ほとんどの多遺伝子スコアソフトは、解決可能なSNPに対しては自動的にストランドフリッピングを行い、解決不可能なミスマッチSNPは削除する。\n",
    "\n",
    "Since we need the target data to know which SNPs have mismatching alleles, we will perform this strand-flipping in the target data.\n",
    "\n",
    "どのSNPがミスマッチした対立遺伝子を持つかを知るためにはターゲットデータが必要なので、このストランドフリッピングをターゲットデータで行う。\n",
    "\n",
    "#### Duplicate SNPs\n",
    "\n",
    "If an error has occurred in the generation of the base data then there may be duplicated SNPs in the base data file. Most PRS software do not allow duplicated SNPs in the base data input and thus they should be removed, using a command such as the one below:\n",
    "\n",
    "ベースデータ作成時にエラーが発生した場合、ベースデータファイル中に重複した SNP が存在する可能性がある。ほとんどのPRSソフトウェアでは、重複SNPのベースデータ入力を許可していないため、以下のようなコマンドを使用して、重複SNPを削除する必要があります："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a770ee0-de7d-4848-8038-12371be99592",
   "metadata": {},
   "outputs": [],
   "source": [
    "gunzip -c Height.gz |\\\n",
    "awk '{seen[$3]++; if(seen[$3]==1){ print}}' |\\\n",
    "gzip - > Height.nodup.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9512fb4c-a47a-484b-8437-f79cc104a5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;31mHeight.gwas.txt.gz\u001b[0m  \u001b[01;31mHeight.gz\u001b[0m  \u001b[01;31mHeight.nodup.gz\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4dad12-a617-4bf9-91d0-3dd3a850c519",
   "metadata": {},
   "source": [
    "The above command does the following:\n",
    "\n",
    "1. Decompresses and reads the Height.gz file\n",
    "2. Count number of time SNP ID was observed, assuming the third column contian the SNP ID (seen[$3]++). If this is the first time seeing this SNP ID, print it.\n",
    "3. Compresses and writes the results to Height.nodup.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afa86e60-78ba-4fa8-a66d-c7008fb3d25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height.gz\n",
      "CHR\tBP\tSNP\tA1\tA2\tN\tSE\tP\tOR\tINFO\tMAF\n",
      "1\t756604\trs3131962\tA\tG\t388028\t0.00301666\t0.483171\t0.997886915712657\t0.890557941364774\t0.369389592764921\n",
      "1\t768448\trs12562034\tA\tG\t388028\t0.00329472\t0.834808\t1.00068731609353\t0.895893511351165\t0.336845754096289\n",
      "1\t779322\trs4040617\tG\tA\t388028\t0.00303344\t0.42897\t0.997603556067569\t0.897508290615237\t0.377368010940814\n",
      "1\t801536\trs79373928\tG\tT\t388028\t0.00841324\t0.808999\t1.00203569922793\t0.908962856432993\t0.483212245374095\n",
      "\n",
      "gzip: stdout: Broken pipe\n",
      "count:529496\n",
      "Height.nodup.gz\n",
      "CHR\tBP\tSNP\tA1\tA2\tN\tSE\tP\tOR\tINFO\tMAF\n",
      "1\t756604\trs3131962\tA\tG\t388028\t0.00301666\t0.483171\t0.997886915712657\t0.890557941364774\t0.369389592764921\n",
      "1\t768448\trs12562034\tA\tG\t388028\t0.00329472\t0.834808\t1.00068731609353\t0.895893511351165\t0.336845754096289\n",
      "1\t779322\trs4040617\tG\tA\t388028\t0.00303344\t0.42897\t0.997603556067569\t0.897508290615237\t0.377368010940814\n",
      "1\t801536\trs79373928\tG\tT\t388028\t0.00841324\t0.808999\t1.00203569922793\t0.908962856432993\t0.483212245374095\n",
      "\n",
      "gzip: stdout: Broken pipe\n",
      "count:529494\n"
     ]
    }
   ],
   "source": [
    "echo \"Height.gz\"\n",
    "gunzip -c Height.gz | head -n 5\n",
    "echo \"count:\"`gunzip -c Height.gz | wc | awk '{print $1}'`\n",
    "echo \"Height.nodup.gz\"\n",
    "gunzip -c Height.nodup.gz | head -n 5\n",
    "echo \"count:\"`gunzip -c Height.nodup.gz | wc | awk '{print $1}'`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34295012-8314-4b7a-8add-e8938d4fea0a",
   "metadata": {},
   "source": [
    "#### Ambiguous SNPs\n",
    "\n",
    "If the base and target data were generated using different genotyping chips and the chromosome strand (+/-) that was used for either is unknown, then it is not possible to pair-up the alleles of ambiguous SNPs (i.e. those with complementary alleles, either C/G or A/T SNPs) across the data sets, because it will be unknown whether the base and target data are referring to the same allele or not. While allele frequencies could be used to infer which alleles are on the same strand, the accuracy of this could be low for SNPs with MAF close to 50% or when the base and target data are from different populations. Therefore, we recommend removing all ambiguous SNPs to avoid introducing this potential source of systematic error.\n",
    "\n",
    "ベースとターゲットのデータが異なるジェノタイピングチップを用いて作成され、どちらかに使用された染色体鎖（+/-）が不明である場合、ベースとターゲットのデータが同じ対立遺伝子を参照しているかどうかが不明であるため、データセット間であいまいなSNP（すなわち、相補的な対立遺伝子を持つSNP、C/GまたはA/TのSNP）の対立遺伝子をペアリングすることはできない。どの対立遺伝子が同じ鎖上にあるのかを推測するために対立遺伝子頻度を用いることもできるが、MAFが50%に近いSNPや、ベースデータとターゲットデータが異なる集団のものである場合、その精度は低くなる可能性がある。したがって、このような系統誤差の原因となる可能性を避けるために、あいまいなSNPはすべて削除することを推奨する。\n",
    "\n",
    "Ambiguous SNPs can be removed in the base data and then there will be no such SNPs in the subsequent analyses, since analyses are performed only on SNPs that overlap between the base and target data. Nonambiguous SNPs can be retained using the following:\n",
    "\n",
    "曖昧なSNPはベースデータから削除することができ、ベースデータとターゲットデータの間で重複するSNPに対してのみ解析が行われるため、その後の解析ではそのようなSNPは存在しない。曖昧でないSNPは以下の方法で残すことができる："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95f3bb09-e8e8-43b0-873a-d507d63f10e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gunzip -c Height.nodup.gz |\\\n",
    "awk '!( ($4==\"A\" && $5==\"T\") || \\\n",
    "        ($4==\"T\" && $5==\"A\") || \\\n",
    "        ($4==\"G\" && $5==\"C\") || \\\n",
    "        ($4==\"C\" && $5==\"G\")) {print}' |\\\n",
    "    gzip > Height.QC.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4fad4ff-9cb9-4d81-882f-5da64164489d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499618\n"
     ]
    }
   ],
   "source": [
    "gunzip -c Height.QC.gz | wc | awk '{print $1}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90475cb-b188-4256-9de9-f7e637457128",
   "metadata": {},
   "source": [
    "#### Sex chromosomes\n",
    "\n",
    "Sometimes sample mislabelling can occur, which may lead to invalid results. One indication of a mislabelled sample is a difference between reported sex and that indicated by the sex chromosomes. While this may be due to a difference in sex and gender identity, it could also reflect mislabeling of samples or misreporting and, thus, individuals in which there is a mismatch between biological and reported sex are typically removed. See the Target Data section in which a sex-check is performed.\n",
    "\n",
    "時には検体の誤標識が起こり、無効な結果につながることがあります。誤ラベリングされたサンプルの兆候の一つは、報告された性と性染色体が示す性との違いである。これは性別や性自認の違いによるものかもしれないが、サンプルの誤ラベリングや報告ミスを反映している可能性もあるため、生物学的性別と報告された性別が不一致の個体は通常除外される。性別チェックが行われる「対象データ」の項を参照のこと。\n",
    "\n",
    "#### Sample overlap\n",
    "\n",
    "Since the target data were simulated there are no overlapping samples between the base and target data here (see the relevant section of the paper for discussion of the importance of avoiding sample overlap).\n",
    "\n",
    "ターゲットデータはシミュレートされたものであるため、ベースデータとターゲットデータの間に重複するサンプルはない（サンプルの重複を避けることの重要性については、論文の関連セクションを参照）。\n",
    "\n",
    "#### Relatedness\n",
    "\n",
    "Closely related individuals within and between the base and the target data may lead to overfitted results, limiting the generalizability of the results (see the relevant sections of the paper). Relatedness within the target data is tested in the Target Data section.\n",
    "\n",
    "ベースデータ内およびターゲットデータ間で密接に関連する個体は、結果の一般化可能性を制限する過剰適合につながる可能性がある（論文の関連セクションを参照）。ターゲットデータ内の関連性は、ターゲットデータのセクションでテストされます。\n",
    "\n",
    "**The Height.QC.gz base data are now ready for using in downstream analyses.**\n",
    "\n",
    "これで、Height.QC.gzベースデータは、下流の解析で使用する準備が整いました。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d80e481-2c3a-474b-9aa4-6c430dd05339",
   "metadata": {},
   "source": [
    "## 2. QC of Target Data\n",
    "\n",
    "### Obtaining the target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e21b6ae7-a34c-4ce1-9430-19d08b3f5f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 36.6M  100 36.6M    0     0  7245k      0  0:00:05  0:00:05 --:--:-- 9962k\n",
      "\u001b[0m\u001b[01;31mEUR.zip\u001b[0m  \u001b[01;31mHeight.gwas.txt.gz\u001b[0m  \u001b[01;31mHeight.gz\u001b[0m  \u001b[01;31mHeight.nodup.gz\u001b[0m  \u001b[01;31mHeight.QC.gz\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#データのダウンロード\n",
    "#https://drive.google.com/u/0/uc?id=1uhJR_3sn7RA8U5iYQbcmTp6vFdQiF4F2&export=download\n",
    "FILE_ID=1uhJR_3sn7RA8U5iYQbcmTp6vFdQiF4F2\n",
    "FILE_NAME=EUR.zip\n",
    "curl -sc /tmp/cookie \"https://drive.google.com/uc?export=download&id=${FILE_ID}\" > /dev/null\n",
    "CODE=\"$(awk '/_warning_/ {print $NF}' /tmp/cookie)\"  \n",
    "curl -Lb /tmp/cookie \"https://drive.google.com/uc?export=download&confirm=${CODE}&id=${FILE_ID}\" -o ${FILE_NAME}\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1de5565-c19d-4e0a-b0c3-9bfe60bc9fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EUR.zip: Zip archive data, at least v2.0 to extract, compression method=deflate\n",
      "Archive:  EUR.zip\n",
      "  inflating: EUR.bed                 \n",
      "  inflating: EUR.bim                 \n",
      "  inflating: EUR.cov                 \n",
      "  inflating: EUR.fam                 \n",
      "  inflating: EUR.height              \n",
      "EUR.bed  EUR.cov  EUR.height  \u001b[0m\u001b[01;31mHeight.gwas.txt.gz\u001b[0m  \u001b[01;31mHeight.nodup.gz\u001b[0m\n",
      "EUR.bim  EUR.fam  \u001b[01;31mEUR.zip\u001b[0m     \u001b[01;31mHeight.gz\u001b[0m           \u001b[01;31mHeight.QC.gz\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "file EUR.zip\n",
    "unzip EUR.zip\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995f20c5-26db-4234-ad12-42eef2e23f96",
   "metadata": {},
   "source": [
    "### QC checklist: Target data\n",
    "#### Sample size\n",
    "We recommend that users only perform PRS analyses on target data of at least 100 individuals. The sample size of our target data here is 503 individuals.\n",
    "\n",
    "少なくとも100人以上の対象データに対してのみPRS分析を行うことを推奨する。ここでの対象データのサンプルサイズは503人である。\n",
    "#### File transfer\n",
    "Usually we do not need to download and transfer the target data file because it is typically generated locally. However, the file should contain an md5sum code in case we send the data file to collaborators who may want to confirm that the file has not changed during the transfer.\n",
    "\n",
    "通常、対象のデータファイルはローカルで生成されるため、ダウンロードして転送する必要はない。しかし、転送中にファイルが変更されていないことを確認したい共同研究者にデータファイルを送る場合に備えて、ファイルにはmd5sumコードを含める必要がある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82188419-adb4-4319-ad89-9e67a61038df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98bcef133f683b1272d3ea5f97742e0e  EUR.bed\n",
      "6b286002904880055a9c94e01522f059  EUR.bim\n",
      "85ed18288c708e095385418517e9c3bd  EUR.cov\n",
      "e7b856f0c7bcaffc8405926d08386e97  EUR.fam\n",
      "dd445ce969a81cded20da5c88b82d4df  EUR.height\n",
      "833aa8ee3a4d9fb591ed61ba44eebe1b  EUR.zip\n"
     ]
    }
   ],
   "source": [
    "md5sum EUR*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d9b574-60a1-47c3-af63-3c58839e6812",
   "metadata": {},
   "source": [
    "#### Genome build\n",
    "As stated in the base data section, the genome build for our base and target data is the same, as it should be.\n",
    "\n",
    "ベースデータのセクションで述べたように、ベースデータとターゲットデータのゲノムビルドは同じである。\n",
    "#### Standard GWAS QC\n",
    "The target data must be quality controlled to at least the standards implemented in GWAS studies, e.g. removing SNPs with low genotyping rate, low minor allele frequency, out of Hardy-Weinberg Equilibrium, removing individuals with low genotyping rate (see Marees et al).The following plink command applies some of these QC metrics to the target data:\n",
    "\n",
    "対象データは、少なくともGWAS研究で実施されている基準で品質管理されていなければならない。例えば、ジェノタイピング率が低いSNP、マイナーアレル頻度が低いSNP、ハーディーワインベルグ平衡から外れたSNP、ジェノタイピング率が低い個体の除去などである（Marees et alを参照）。以下のplinkコマンドは、これらのQCメトリクスの一部を対象データに適用する："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4e7ac6e-5a9f-488d-b089-e62fdd2f9a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLINK v1.90b7 64-bit (16 Jan 2023)             www.cog-genomics.org/plink/1.9/\n",
      "(C) 2005-2023 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to EUR.QC.log.\n",
      "Options in effect:\n",
      "  --bfile EUR\n",
      "  --geno 0.01\n",
      "  --hwe 1e-6\n",
      "  --maf 0.01\n",
      "  --make-just-fam\n",
      "  --mind 0.01\n",
      "  --out EUR.QC\n",
      "  --write-snplist\n",
      "\n",
      "257564 MB RAM detected; reserving 128782 MB for main workspace.\n",
      "551892 variants loaded from .bim file.\n",
      "503 people (240 males, 263 females) loaded from .fam.\n",
      "14 people removed due to missing genotype data (--mind).\n",
      "IDs written to EUR.QC.irem .\n",
      "Using 1 thread (no multithreaded calculations invoked).\n",
      "Before main variant filters, 489 founders and 0 nonfounders present.\n",
      "Calculating allele frequencies... 10111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989 done.\n",
      "Warning: 1806 het. haploid genotypes present (see EUR.QC.hh ); many commands\n",
      "treat these as missing.\n",
      "Total genotyping rate in remaining samples is 0.999816.\n",
      "5353 variants removed due to missing genotype data (--geno).\n",
      "Warning: --hwe observation counts vary by more than 10%, due to the X\n",
      "chromosome.  You may want to use a less stringent --hwe p-value threshold for X\n",
      "chromosome variants.\n",
      "--hwe: 944 variants removed due to Hardy-Weinberg exact test.\n",
      "5061 variants removed due to minor allele threshold(s)\n",
      "(--maf/--max-maf/--mac/--max-mac).\n",
      "540534 variants and 489 people pass filters and QC.\n",
      "Note: No phenotypes present.\n",
      "List of variant IDs written to EUR.QC.snplist .\n",
      "--make-just-fam to EUR.QC.fam ... done.\n"
     ]
    }
   ],
   "source": [
    "plink \\\n",
    "    --bfile EUR \\\n",
    "    --maf 0.01 \\\n",
    "    --hwe 1e-6 \\\n",
    "    --geno 0.01 \\\n",
    "    --mind 0.01 \\\n",
    "    --write-snplist \\\n",
    "    --make-just-fam \\\n",
    "    --out EUR.QC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315553de-8886-4f81-9c9e-742bac5aa9eb",
   "metadata": {},
   "source": [
    ">Normally, we can generate a new genotype file using the new sample list. However, this will use up a lot of storage space. Using plink's --extract, --exclude, --keep, --remove, --make-just-fam and --write-snplist functions, we can work solely on the list of samples and SNPs without duplicating the genotype file, reducing the storage space usage.\n",
    ">\n",
    ">通常、新しいサンプルリストを用いて新しい遺伝子型ファイルを生成することができます。しかし、これでは多くの記憶容量を使うことになる。plinkの--extract関数、--exclude関数、--keep関数、--remove関数、--make-just-fam関数、--write-snplist関数を使えば、遺伝子型ファイルを複製することなく、サンプルとSNPのリストだけで作業することができ、ストレージの使用量を減らすことができる。\n",
    "\n",
    "Very high or low heterozygosity rates in individuals could be due to DNA contamination or to high levels of inbreeding. Therefore, samples with extreme heterozygosity are typically removed prior to downstream analyses.\n",
    "\n",
    "個体内のヘテロ接合率が非常に高いか低いのは、DNAのコンタミネーションや近親交配が多いためである可能性がある。従って、極端なヘテロ接合率を持つサンプルは、通常、下流の解析の前に除去される。\n",
    "\n",
    "First, we perform pruning to remove highly correlated SNPs:\n",
    "\n",
    "まず、相関性の高いSNPを除去するためにプルーニングを行う："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb0e80a0-ac1d-4c00-886a-375565111146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLINK v1.90b7 64-bit (16 Jan 2023)             www.cog-genomics.org/plink/1.9/\n",
      "(C) 2005-2023 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to EUR.QC.log.\n",
      "Options in effect:\n",
      "  --bfile EUR\n",
      "  --extract EUR.QC.snplist\n",
      "  --indep-pairwise 200 50 0.25\n",
      "  --keep EUR.QC.fam\n",
      "  --out EUR.QC\n",
      "\n",
      "257564 MB RAM detected; reserving 128782 MB for main workspace.\n",
      "551892 variants loaded from .bim file.\n",
      "503 people (240 males, 263 females) loaded from .fam.\n",
      "--extract: 540534 variants remaining.\n",
      "--keep: 489 people remaining.\n",
      "Using 1 thread (no multithreaded calculations invoked).\n",
      "Before main variant filters, 489 founders and 0 nonfounders present.\n",
      "Calculating allele frequencies... 10111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989 done.\n",
      "Warning: 1273 het. haploid genotypes present (see EUR.QC.hh ); many commands\n",
      "treat these as missing.\n",
      "Total genotyping rate in remaining samples is 0.999919.\n",
      "540534 variants and 489 people pass filters and QC.\n",
      "Note: No phenotypes present.\n",
      "Pruned 20214 variants from chromosome 1, leaving 21127.\n",
      "Pruned 20984 variants from chromosome 2, leaving 20879.\n",
      "Pruned 17463 variants from chromosome 3, leaving 17812.\n",
      "Pruned 16344 variants from chromosome 4, leaving 16690.\n",
      "Pruned 15027 variants from chromosome 5, leaving 15981.\n",
      "Pruned 20731 variants from chromosome 6, leaving 15475.\n",
      "Pruned 14046 variants from chromosome 7, leaving 14606.\n",
      "Pruned 13289 variants from chromosome 8, leaving 13667.\n",
      "Pruned 10723 variants from chromosome 9, leaving 11951.\n",
      "Pruned 12722 variants from chromosome 10, leaving 13383.\n",
      "Pruned 13053 variants from chromosome 11, leaving 12666.\n",
      "Pruned 11654 variants from chromosome 12, leaving 12500.\n",
      "Pruned 8429 variants from chromosome 13, leaving 9609.\n",
      "Pruned 8072 variants from chromosome 14, leaving 8791.\n",
      "Pruned 7978 variants from chromosome 15, leaving 8470.\n",
      "Pruned 8808 variants from chromosome 16, leaving 9500.\n",
      "Pruned 8032 variants from chromosome 17, leaving 8724.\n",
      "Pruned 7204 variants from chromosome 18, leaving 8560.\n",
      "Pruned 7014 variants from chromosome 19, leaving 6726.\n",
      "Pruned 6341 variants from chromosome 20, leaving 7508.\n",
      "Pruned 3629 variants from chromosome 21, leaving 4280.\n",
      "Pruned 4085 variants from chromosome 22, leaving 4323.\n",
      "Pruned 16235 variants from chromosome 23, leaving 5229.\n",
      "Pruning complete.  272077 of 540534 variants removed.\n",
      "Marker lists written to EUR.QC.prune.in and EUR.QC.prune.out .\n"
     ]
    }
   ],
   "source": [
    "plink \\\n",
    "    --bfile EUR \\\n",
    "    --keep EUR.QC.fam \\\n",
    "    --extract EUR.QC.snplist \\\n",
    "    --indep-pairwise 200 50 0.25 \\\n",
    "    --out EUR.QC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027a789c-cd4d-4449-967e-9f25225face5",
   "metadata": {},
   "source": [
    "This will generate two files 1) EUR.QC.prune.in and 2) EUR.QC.prune.out. All SNPs within EUR.QC.prune.in have a pairwise r2<0.25.\n",
    "\n",
    "これにより2つのファイル1) EUR.QC.prune.inと2) EUR.QC.prune.outが生成される。EUR.QC.prune.in内のSNPはすべてペアワイズr2<0.25である。\n",
    "\n",
    "Heterozygosity rates can then be computed using plink:\n",
    "\n",
    "ヘテロ接合率はplinkを使って計算できる："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b55db1bb-271e-4b34-ba8f-e32875602186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLINK v1.90b7 64-bit (16 Jan 2023)             www.cog-genomics.org/plink/1.9/\n",
      "(C) 2005-2023 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to EUR.QC.log.\n",
      "Options in effect:\n",
      "  --bfile EUR\n",
      "  --extract EUR.QC.prune.in\n",
      "  --het\n",
      "  --keep EUR.QC.fam\n",
      "  --out EUR.QC\n",
      "\n",
      "257564 MB RAM detected; reserving 128782 MB for main workspace.\n",
      "551892 variants loaded from .bim file.\n",
      "503 people (240 males, 263 females) loaded from .fam.\n",
      "--extract: 268457 variants remaining.\n",
      "--keep: 489 people remaining.\n",
      "Using 1 thread (no multithreaded calculations invoked).\n",
      "Before main variant filters, 489 founders and 0 nonfounders present.\n",
      "Calculating allele frequencies... 10111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989 done.\n",
      "Warning: 558 het. haploid genotypes present (see EUR.QC.hh ); many commands\n",
      "treat these as missing.\n",
      "Total genotyping rate in remaining samples is 0.999958.\n",
      "268457 variants and 489 people pass filters and QC.\n",
      "Note: No phenotypes present.\n",
      "--het: 263228 variants scanned, report written to EUR.QC.het .\n"
     ]
    }
   ],
   "source": [
    "plink \\\n",
    "    --bfile EUR \\\n",
    "    --extract EUR.QC.prune.in \\\n",
    "    --keep EUR.QC.fam \\\n",
    "    --het \\\n",
    "    --out EUR.QC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ec24f2-c9fd-4a91-85ca-790b72082ff3",
   "metadata": {},
   "source": [
    "This will generate the EUR.QC.het file, which contains F coefficient estimates for assessing heterozygosity. We will remove individuals with F coefficients that are more than 3 standard deviation (SD) units from the mean, which can be performed using the following R command (assuming that you have R downloaded, then you can open an R session by typing R in your terminal):\n",
    "\n",
    "これはヘテロ接合性を評価するためのF係数推定値を含むEUR.QC.hetファイルを生成する。平均から3標準偏差(SD)単位以上のF係数を持つ個体を削除します。これは、以下のRコマンドで実行できます（Rがダウンロードされていることを仮定して、ターミナルでRとタイプしてRセッションを開くことができます）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7012b2b1-10b2-44a6-b2cd-bb48ea2be315",
   "metadata": {},
   "outputs": [],
   "source": [
    "echo 'dat <- read.table(\"EUR.QC.het\", header=T) # Read in the EUR.het file, specify it has header' > het.R\n",
    "echo 'm <- mean(dat$F) # Calculate the mean' >> het.R\n",
    "echo 's <- sd(dat$F) # Calculate the SD' >> het.R\n",
    "echo 'valid <- subset(dat, F <= m+3*s & F >= m-3*s) # Get any samples with F coefficient within 3 SD of the population mean' >> het.R\n",
    "echo 'write.table(valid[,c(1,2)], \"EUR.valid.sample\", quote=F, row.names=F) # print FID and IID for valid samples' >> het.R\n",
    "\n",
    "Rscript --no-save het.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "66a21eba-45e9-4122-b1bd-0f7b1c214968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EUR.bed  EUR.height  EUR.QC.irem       EUR.QC.snplist      \u001b[0m\u001b[01;31mHeight.gz\u001b[0m\n",
      "EUR.bim  EUR.QC.fam  EUR.QC.log        EUR.valid.sample    \u001b[01;31mHeight.nodup.gz\u001b[0m\n",
      "EUR.cov  EUR.QC.het  EUR.QC.prune.in   \u001b[01;31mEUR.zip\u001b[0m             \u001b[01;31mHeight.QC.gz\u001b[0m\n",
      "EUR.fam  EUR.QC.hh   EUR.QC.prune.out  \u001b[01;31mHeight.gwas.txt.gz\u001b[0m  het.R\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd345c1c-18eb-4c72-8eab-17f28cd0163f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID IID\n",
      "HG00096 HG00096\n",
      "HG00097 HG00097\n",
      "HG00099 HG00099\n",
      "HG00101 HG00101\n",
      "HG00102 HG00102\n",
      "HG00103 HG00103\n",
      "HG00105 HG00105\n",
      "HG00107 HG00107\n",
      "HG00108 HG00108\n"
     ]
    }
   ],
   "source": [
    "head EUR.valid.sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "29cb5af1-f33c-4868-8b81-b8231a2f14c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 488  976 7800 EUR.valid.sample\n",
      "  490  2940 35280 EUR.QC.het\n"
     ]
    }
   ],
   "source": [
    "wc EUR.valid.sample\n",
    "wc EUR.QC.het"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d605c68-6a37-44d8-b903-50237ee7a5b1",
   "metadata": {},
   "source": [
    "#### Ambiguous SNPs\n",
    "These were removed during the base data QC.\n",
    "\n",
    "これらはベースデータのQCで削除された。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f074d2ff-40e7-4447-8798-449ece2f5b20",
   "metadata": {},
   "source": [
    "**【重要】**\n",
    "\n",
    "**ここまでのファイルをhmiwa-lab直下でやってしまったが、大きなデータはhmiwa1の方へ移しておかねばならなかった**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06a93cdb-675d-471d-9431-6f511f9e6554",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/hmiwa/hmiwa-lab/d_20231023/03_231113_TutorialPRS\n",
    "mkdir -p ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS\n",
    "mv data ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbc9c0ce-0d63-40b3-97f9-575b058cd04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hmiwa-lab\n",
      "PRSTutorial1103.ipynb\n",
      "hmiwa1\n",
      "EUR.bed  EUR.height  EUR.QC.irem       EUR.QC.snplist      \u001b[0m\u001b[01;31mHeight.gz\u001b[0m\n",
      "EUR.bim  EUR.QC.fam  EUR.QC.log        EUR.valid.sample    \u001b[01;31mHeight.nodup.gz\u001b[0m\n",
      "EUR.cov  EUR.QC.het  EUR.QC.prune.in   \u001b[01;31mEUR.zip\u001b[0m             \u001b[01;31mHeight.QC.gz\u001b[0m\n",
      "EUR.fam  EUR.QC.hh   EUR.QC.prune.out  \u001b[01;31mHeight.gwas.txt.gz\u001b[0m  het.R\n"
     ]
    }
   ],
   "source": [
    "echo \"hmiwa-lab\"\n",
    "ls ~/hmiwa/hmiwa-lab/d_20231023/03_231113_TutorialPRS\n",
    "echo \"hmiwa1\"\n",
    "ls ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adb893b-828b-46fa-9264-58b83bf4a807",
   "metadata": {},
   "source": [
    "#### Mismatching SNPs\n",
    "SNPs that have mismatching alleles reported in the base and target data may be resolvable by strand-flipping the alleles to their complementary alleles in e.g. the target data, such as for a SNP with A/C in the base data and G/T in the target. This can be achieved with the following steps:\n",
    "\n",
    "ベースデータとターゲットデータで報告されたアレルが不一致のSNPは、例えば、ベースデータでA/C、ターゲットデータでG/TのSNPのように、アレルがターゲットデータで相補的なアレルにストランドフリップすることで解決できる場合がある。これは以下のステップで達成できる：\n",
    "\n",
    ">Most PRS software will perform strand-flipping automatically, thus this step is usually not required.\n",
    ">\n",
    ">ほとんどのPRSソフトウェアは自動的にストランドフリップを行うので、通常このステップは必要ない。\n",
    "\n",
    "##### 1. Load the bim file, the summary statistic and the QC SNP list into R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f331f94-5535-4dfd-b87b-d7c8fdf7c317",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data\n",
    "#1-4は連続して実行すること\n",
    "cat <<EOL > ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data/mismatchSNP.R\n",
    "# Read in bim file\n",
    "bim <- read.table(\"EUR.bim\")\n",
    "colnames(bim) <- c(\"CHR\", \"SNP\", \"CM\", \"BP\", \"B.A1\", \"B.A2\")\n",
    "# Read in QCed SNPs\n",
    "qc <- read.table(\"EUR.QC.snplist\", header = F, stringsAsFactors = F)\n",
    "# Read in the GWAS data\n",
    "height <-\n",
    "    read.table(gzfile(\"Height.QC.gz\"),\n",
    "            header = T,\n",
    "            stringsAsFactors = F, \n",
    "            sep=\"\\t\")\n",
    "# Change all alleles to upper case for easy comparison\n",
    "height\\$A1 <- toupper(height\\$A1)\n",
    "height\\$A2 <- toupper(height\\$A2)\n",
    "bim\\$B.A1 <- toupper(bim\\$B.A1)\n",
    "bim\\$B.A2 <- toupper(bim\\$B.A2)\n",
    "EOL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7d88fa-526c-42a9-a45c-43f6283948ea",
   "metadata": {},
   "source": [
    "##### 2. Identify SNPs that require strand flipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94ec1506-b954-40d8-a8e2-373a403c0011",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat <<EOL >> ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data/mismatchSNP.R\n",
    "# Merge summary statistic with target\n",
    "info <- merge(bim, height, by = c(\"SNP\", \"CHR\", \"BP\"))\n",
    "# Filter QCed SNPs\n",
    "info <- info[info\\$SNP %in% qc\\$V1,]\n",
    "# Function for finding the complementary allele\n",
    "complement <- function(x) {\n",
    "    switch (\n",
    "        x,\n",
    "        \"A\" = \"T\",\n",
    "        \"C\" = \"G\",\n",
    "        \"T\" = \"A\",\n",
    "        \"G\" = \"C\",\n",
    "        return(NA)\n",
    "    )\n",
    "}\n",
    "# Get SNPs that have the same alleles across base and target\n",
    "info.match <- subset(info, A1 == B.A1 & A2 == B.A2)\n",
    "# Identify SNPs that are complementary between base and target\n",
    "info\\$C.A1 <- sapply(info\\$B.A1, complement)\n",
    "info\\$C.A2 <- sapply(info\\$B.A2, complement)\n",
    "info.complement <- subset(info, A1 == C.A1 & A2 == C.A2)\n",
    "# Update the complementary alleles in the bim file\n",
    "# This allow us to match the allele in subsequent analysis\n",
    "complement.snps <- bim\\$SNP %in% info.complement\\$SNP\n",
    "bim[complement.snps,]\\$B.A1 <-\n",
    "    sapply(bim[complement.snps,]\\$B.A1, complement)\n",
    "bim[complement.snps,]\\$B.A2 <-\n",
    "    sapply(bim[complement.snps,]\\$B.A2, complement)\n",
    "EOL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61357c56-1820-4f14-9b06-3376441dfeea",
   "metadata": {},
   "source": [
    "##### 3. Identify SNPs that require recoding in the target (to ensure the coding allele in the target data is the effective allele in the base summary statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c026f59-dad9-4d7f-9660-53aef2e720e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat <<EOL >> ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data/mismatchSNP.R\n",
    "# identify SNPs that need recoding\n",
    "info.recode <- subset(info, A1 == B.A2 & A2 == B.A1)\n",
    "# Update the recode SNPs\n",
    "recode.snps <- bim\\$SNP %in% info.recode\\$SNP\n",
    "tmp <- bim[recode.snps,]\\$B.A1\n",
    "bim[recode.snps,]\\$B.A1 <- bim[recode.snps,]\\$B.A2\n",
    "bim[recode.snps,]\\$B.A2 <- tmp\n",
    "\n",
    "# identify SNPs that need recoding & complement\n",
    "info.crecode <- subset(info, A1 == C.A2 & A2 == C.A1)\n",
    "# Update the recode + strand flip SNPs\n",
    "com.snps <- bim\\$SNP %in% info.crecode\\$SNP\n",
    "tmp <- bim[com.snps,]\\$B.A1\n",
    "bim[com.snps,]\\$B.A1 <- as.character(sapply(bim[com.snps,]\\$B.A2, complement))\n",
    "bim[com.snps,]\\$B.A2 <- as.character(sapply(tmp, complement))\n",
    "\n",
    "# Output updated bim file\n",
    "write.table(\n",
    "    bim[,c(\"SNP\", \"B.A1\")],\n",
    "    \"EUR.a1\",\n",
    "    quote = F,\n",
    "    row.names = F,\n",
    "    col.names = F,\n",
    "    sep=\"\\t\"\n",
    ")\n",
    "EOL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d2f8ca-54f2-4ed4-8402-8bbd3ef4a201",
   "metadata": {},
   "source": [
    "##### 4. Identify SNPs that have different allele in base and target (usually due to difference in genome build or Indel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b28472ba-bf72-4ebb-b474-1e5a4caf5ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat <<EOL >> ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data/mismatchSNP.R\n",
    "mismatch <-\n",
    "    bim\\$SNP[!(bim\\$SNP %in% info.match\\$SNP |\n",
    "                bim\\$SNP %in% info.complement\\$SNP | \n",
    "                bim\\$SNP %in% info.recode\\$SNP |\n",
    "                bim\\$SNP %in% info.crecode\\$SNP)]\n",
    "write.table(\n",
    "    mismatch,\n",
    "    \"EUR.mismatch\",\n",
    "    quote = F,\n",
    "    row.names = F,\n",
    "    col.names = F\n",
    ")\n",
    "EOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a093b82-c9f4-45b9-90c8-32a1d29c0fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Read in bim file\n",
      "bim <- read.table(\"EUR.bim\")\n",
      "colnames(bim) <- c(\"CHR\", \"SNP\", \"CM\", \"BP\", \"B.A1\", \"B.A2\")\n",
      "# Read in QCed SNPs\n",
      "qc <- read.table(\"EUR.QC.snplist\", header = F, stringsAsFactors = F)\n",
      "# Read in the GWAS data\n",
      "height <-\n",
      "    read.table(gzfile(\"Height.QC.gz\"),\n",
      "            header = T,\n",
      "            stringsAsFactors = F, \n",
      "            sep=\"\\t\")\n",
      "# Change all alleles to upper case for easy comparison\n",
      "height$A1 <- toupper(height$A1)\n",
      "height$A2 <- toupper(height$A2)\n",
      "bim$B.A1 <- toupper(bim$B.A1)\n",
      "bim$B.A2 <- toupper(bim$B.A2)\n",
      "# Merge summary statistic with target\n",
      "info <- merge(bim, height, by = c(\"SNP\", \"CHR\", \"BP\"))\n",
      "# Filter QCed SNPs\n",
      "info <- info[info$SNP %in% qc$V1,]\n",
      "# Function for finding the complementary allele\n",
      "complement <- function(x) {\n",
      "    switch (\n",
      "        x,\n",
      "        \"A\" = \"T\",\n",
      "        \"C\" = \"G\",\n",
      "        \"T\" = \"A\",\n",
      "        \"G\" = \"C\",\n",
      "        return(NA)\n",
      "    )\n",
      "}\n",
      "# Get SNPs that have the same alleles across base and target\n",
      "info.match <- subset(info, A1 == B.A1 & A2 == B.A2)\n",
      "# Identify SNPs that are complementary between base and target\n",
      "info$C.A1 <- sapply(info$B.A1, complement)\n",
      "info$C.A2 <- sapply(info$B.A2, complement)\n",
      "info.complement <- subset(info, A1 == C.A1 & A2 == C.A2)\n",
      "# Update the complementary alleles in the bim file\n",
      "# This allow us to match the allele in subsequent analysis\n",
      "complement.snps <- bim$SNP %in% info.complement$SNP\n",
      "bim[complement.snps,]$B.A1 <-\n",
      "    sapply(bim[complement.snps,]$B.A1, complement)\n",
      "bim[complement.snps,]$B.A2 <-\n",
      "    sapply(bim[complement.snps,]$B.A2, complement)\n",
      "# identify SNPs that need recoding\n",
      "info.recode <- subset(info, A1 == B.A2 & A2 == B.A1)\n",
      "# Update the recode SNPs\n",
      "recode.snps <- bim$SNP %in% info.recode$SNP\n",
      "tmp <- bim[recode.snps,]$B.A1\n",
      "bim[recode.snps,]$B.A1 <- bim[recode.snps,]$B.A2\n",
      "bim[recode.snps,]$B.A2 <- tmp\n",
      "\n",
      "# identify SNPs that need recoding & complement\n",
      "info.crecode <- subset(info, A1 == C.A2 & A2 == C.A1)\n",
      "# Update the recode + strand flip SNPs\n",
      "com.snps <- bim$SNP %in% info.crecode$SNP\n",
      "tmp <- bim[com.snps,]$B.A1\n",
      "bim[com.snps,]$B.A1 <- as.character(sapply(bim[com.snps,]$B.A2, complement))\n",
      "bim[com.snps,]$B.A2 <- as.character(sapply(tmp, complement))\n",
      "\n",
      "# Output updated bim file\n",
      "write.table(\n",
      "    bim[,c(\"SNP\", \"B.A1\")],\n",
      "    \"EUR.a1\",\n",
      "    quote = F,\n",
      "    row.names = F,\n",
      "    col.names = F,\n",
      "    sep=\"\\t\"\n",
      ")\n",
      "mismatch <-\n",
      "    bim$SNP[!(bim$SNP %in% info.match$SNP |\n",
      "                bim$SNP %in% info.complement$SNP | \n",
      "                bim$SNP %in% info.recode$SNP |\n",
      "                bim$SNP %in% info.crecode$SNP)]\n",
      "write.table(\n",
      "    mismatch,\n",
      "    \"EUR.mismatch\",\n",
      "    quote = F,\n",
      "    row.names = F,\n",
      "    col.names = F\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cat ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data/mismatchSNP.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb2d6345-e908-4e53-a4e5-be6ccdb20354",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rscript ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data/mismatchSNP.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a52fa7b1-4640-4088-a244-067bbf25536e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EUR.a1   EUR.height    EUR.QC.irem       EUR.valid.sample    \u001b[0m\u001b[01;31mHeight.QC.gz\u001b[0m\n",
      "EUR.bed  EUR.mismatch  EUR.QC.log        \u001b[01;31mEUR.zip\u001b[0m             het.R\n",
      "EUR.bim  EUR.QC.fam    EUR.QC.prune.in   \u001b[01;31mHeight.gwas.txt.gz\u001b[0m  mismatchSNP.R\n",
      "EUR.cov  EUR.QC.het    EUR.QC.prune.out  \u001b[01;31mHeight.gz\u001b[0m\n",
      "EUR.fam  EUR.QC.hh     EUR.QC.snplist    \u001b[01;31mHeight.nodup.gz\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ls ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5498c578-d867-4466-a945-fbaf7ea6e9f3",
   "metadata": {},
   "source": [
    "#### Duplicate SNPs\n",
    "Make sure to remove any duplicate SNPs in your target data (these target data were simulated and so include no duplicated SNPs).\n",
    "\n",
    "ターゲットデータ中の重複SNPを必ず削除してください（これらのターゲットデータはシミュレートされたため、重複SNPは含まれていません）。\n",
    "#### Sex chromosomes\n",
    "Sometimes sample mislabelling can occur, which may lead to invalid results. One indication of a mislabelled sample is a difference between reported sex and that indicated by the sex chromosomes. While this may be due to a difference in sex and gender identity, it could also reflect mislabeling of samples or misreporting and, thus, individuals in which there is a mismatch between biological and reported sex are typically removed. A sex check can be performed in PLINK, in which individuals are called as females if their X chromosome homozygosity estimate (F statistic) is < 0.2 and as males if the estimate is > 0.8.\n",
    "\n",
    "時には検体の誤ラベリングが起こり、無効な結果につながることがあります。誤ラベリングされたサンプルの兆候の一つは、報告された性と性染色体が示す性との違いである。これは性別や性自認の違いに起因する場合もありますが、サンプルの誤ラベリングや誤った報告を反映している可能性もあり、そのため、生物学的性別と報告された性別の間に不一致がある個体は通常除外されます。性チェックはPLINKで行うことができ、X染色体のホモ接合性の推定値（F統計量）が0.2未満の個体はメス、0.8以上の個体はオスと呼ばれる。\n",
    "\n",
    "Before performing a sex check, pruning should be performed (see here). A sex check can then easily be conducted using plink\n",
    "\n",
    "性チェックを行う前に、剪定を行うべきである（こちらを参照）。その後、plinkを使って簡単に雌雄チェックを行うことができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "245185f6-38ff-4856-8739-671a6e648cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLINK v1.90b7 64-bit (16 Jan 2023)             www.cog-genomics.org/plink/1.9/\n",
      "(C) 2005-2023 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to EUR.QC.log.\n",
      "Options in effect:\n",
      "  --bfile EUR\n",
      "  --check-sex\n",
      "  --extract EUR.QC.prune.in\n",
      "  --keep EUR.valid.sample\n",
      "  --out EUR.QC\n",
      "\n",
      "257564 MB RAM detected; reserving 128782 MB for main workspace.\n",
      "551892 variants loaded from .bim file.\n",
      "503 people (240 males, 263 females) loaded from .fam.\n",
      "--extract: 268457 variants remaining.\n",
      "--keep: 487 people remaining.\n",
      "Using 1 thread (no multithreaded calculations invoked).\n",
      "Before main variant filters, 487 founders and 0 nonfounders present.\n",
      "Calculating allele frequencies... 10111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989 done.\n",
      "Warning: 558 het. haploid genotypes present (see EUR.QC.hh ); many commands\n",
      "treat these as missing.\n",
      "Total genotyping rate in remaining samples is 0.999958.\n",
      "268457 variants and 487 people pass filters and QC.\n",
      "Note: No phenotypes present.\n",
      "--check-sex: 5229 Xchr and 0 Ychr variant(s) scanned, 4 problems detected.\n",
      "Report written to EUR.QC.sexcheck .\n"
     ]
    }
   ],
   "source": [
    "plink \\\n",
    "    --bfile EUR \\\n",
    "    --extract EUR.QC.prune.in \\\n",
    "    --keep EUR.valid.sample \\\n",
    "    --check-sex \\\n",
    "    --out EUR.QC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c1383a-fcf0-4d12-a775-f413957331fc",
   "metadata": {},
   "source": [
    "This will generate a file called EUR.QC.sexcheck containing the F-statistics for each individual. Individuals are typically called as being biologically male if the F-statistic is > 0.8 and biologically female if F < 0.2.\n",
    "\n",
    "これにより、各個体のF統計量を含むEUR.QC.sexcheckというファイルが生成される。F統計量が0.8以上の個体は生物学的に男性であり、0.2未満の個体は生物学的に女性であると通常呼ばれます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c830d11d-b59b-4f52-873d-8673033dae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat <<EOL >> ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data/sexcheck.R\n",
    "# Read in file\n",
    "valid <- read.table(\"EUR.valid.sample\", header=T)\n",
    "dat <- read.table(\"EUR.QC.sexcheck\", header=T)\n",
    "valid <- subset(dat, STATUS==\"OK\" & FID %in% valid\\$FID)\n",
    "write.table(valid[,c(\"FID\", \"IID\")], \"EUR.QC.valid\", row.names=F, col.names=F, sep=\"\\t\", quote=F) \n",
    "EOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e64aef4a-d297-44be-b828-603b622384c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Read in file\n",
      "valid <- read.table(\"EUR.valid.sample\", header=T)\n",
      "dat <- read.table(\"EUR.QC.sexcheck\", header=T)\n",
      "valid <- subset(dat, STATUS==\"OK\" & FID %in% valid$FID)\n",
      "write.table(valid[,c(\"FID\", \"IID\")], \"EUR.QC.valid\", row.names=F, col.names=F, sep=\"\\t\", quote=F) \n"
     ]
    }
   ],
   "source": [
    "cat ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data/sexcheck.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11b1ca83-cb29-4ae8-8996-60b46c446882",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rscript ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data/sexcheck.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a905c2e5-44f5-4ba4-b4eb-9187979022b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EUR.a1      EUR.mismatch  EUR.QC.prune.in   \u001b[0m\u001b[01;31mEUR.zip\u001b[0m             mismatchSNP.R\n",
      "EUR.bed     EUR.QC.fam    EUR.QC.prune.out  \u001b[01;31mHeight.gwas.txt.gz\u001b[0m  sexcheck.R\n",
      "EUR.bim     EUR.QC.het    EUR.QC.sexcheck   \u001b[01;31mHeight.gz\u001b[0m\n",
      "EUR.cov     EUR.QC.hh     EUR.QC.snplist    \u001b[01;31mHeight.nodup.gz\u001b[0m\n",
      "EUR.fam     EUR.QC.irem   EUR.QC.valid      \u001b[01;31mHeight.QC.gz\u001b[0m\n",
      "EUR.height  EUR.QC.log    EUR.valid.sample  het.R\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c6c6fba-0a74-4bec-8eca-3e8785333dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HG00096\tHG00096\n",
      "HG00097\tHG00097\n",
      "HG00099\tHG00099\n",
      "HG00101\tHG00101\n",
      "HG00102\tHG00102\n",
      "HG00103\tHG00103\n",
      "HG00105\tHG00105\n",
      "HG00107\tHG00107\n",
      "HG00108\tHG00108\n",
      "HG00109\tHG00109\n"
     ]
    }
   ],
   "source": [
    "head EUR.QC.valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7d83605-1e1e-4e73-9e90-63f6477acea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      FID       IID       PEDSEX       SNPSEX       STATUS            F\n",
      "  HG00096   HG00096            1            1           OK            1\n",
      "  HG00097   HG00097            2            2           OK       -0.217\n",
      "  HG00099   HG00099            2            2           OK      -0.1848\n",
      "  HG00101   HG00101            1            1           OK            1\n",
      "  HG00102   HG00102            2            2           OK      -0.3558\n",
      "  HG00103   HG00103            1            1           OK            1\n",
      "  HG00105   HG00105            1            1           OK            1\n",
      "  HG00107   HG00107            1            1           OK            1\n",
      "  HG00108   HG00108            1            1           OK            1\n"
     ]
    }
   ],
   "source": [
    "head EUR.QC.sexcheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94c38189-9610-4f51-83ab-9294ef8ec799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 483  966 7728 EUR.QC.valid\n",
      "  488  2928 35136 EUR.QC.sexcheck\n"
     ]
    }
   ],
   "source": [
    "wc EUR.QC.valid\n",
    "wc EUR.QC.sexcheck"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c798cce8-4f11-4717-a2ba-760b3e84526c",
   "metadata": {},
   "source": [
    "#### Sample overlap\n",
    "Since the target data were simulated there are no overlapping samples between the base and target data here (see the relevant section of the paper for discussion of the importance of avoiding sample overlap).\n",
    "\n",
    "ターゲットデータはシミュレートされたものであるため、ベースデータとターゲットデータの間に重複するサンプルはない（サンプルの重複を避けることの重要性については、論文の関連セクションを参照）。\n",
    "#### Relatedness\n",
    "Closely related individuals in the target data may lead to overfitted results, limiting the generalisability of the results.\r\n",
    "対象データ中の近縁の個体は、過剰適合を引き起こし、結果の一般性を制限する可能性がある。\n",
    "\n",
    "\r\n",
    "Before calculating the relatedness, pruning should be performed (see here). Individuals that have a first or second degree relative in the sample\n",
    "\r",
    "π\r\n",
    ">\r",
    "0.125\r\n",
    ") can be removed with the following co\n",
    "近縁度を計算する前に、プルーニングを行うべきである（こちらを参照）。サンプル中に1度または2度の近親者がいる個体（π>0.125）は、以下のコマンドで削除できます：ta file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b54a7544-081d-4303-bd59-a3a20576eca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLINK v1.90b7 64-bit (16 Jan 2023)             www.cog-genomics.org/plink/1.9/\n",
      "(C) 2005-2023 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to EUR.QC.log.\n",
      "Options in effect:\n",
      "  --bfile EUR\n",
      "  --extract EUR.QC.prune.in\n",
      "  --keep EUR.QC.valid\n",
      "  --out EUR.QC\n",
      "  --rel-cutoff 0.125\n",
      "\n",
      "257564 MB RAM detected; reserving 128782 MB for main workspace.\n",
      "551892 variants loaded from .bim file.\n",
      "503 people (240 males, 263 females) loaded from .fam.\n",
      "--extract: 268457 variants remaining.\n",
      "--keep: 483 people remaining.\n",
      "Using up to 63 threads (change this with --threads).\n",
      "Before main variant filters, 483 founders and 0 nonfounders present.\n",
      "Calculating allele frequencies... 10111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989 done.\n",
      "Total genotyping rate in remaining samples is 0.999957.\n",
      "268457 variants and 483 people pass filters and QC (before --rel-cutoff).\n",
      "Note: No phenotypes present.\n",
      "Excluding 5229 variants on non-autosomes from relationship matrix calc.\n",
      "Relationship matrix calculation complete.\n",
      "0 people excluded by --rel-cutoff.\n",
      "Remaining sample IDs written to EUR.QC.rel.id .\n"
     ]
    }
   ],
   "source": [
    "plink \\\n",
    "    --bfile EUR \\\n",
    "    --extract EUR.QC.prune.in \\\n",
    "    --keep EUR.QC.valid \\\n",
    "    --rel-cutoff 0.125 \\\n",
    "    --out EUR.QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "475b6a58-e468-48a2-928a-aa37e6242768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EUR.a1      EUR.mismatch  EUR.QC.prune.in   EUR.valid.sample    het.R\n",
      "EUR.bed     EUR.QC.fam    EUR.QC.prune.out  \u001b[0m\u001b[01;31mEUR.zip\u001b[0m             mismatchSNP.R\n",
      "EUR.bim     EUR.QC.het    EUR.QC.rel.id     \u001b[01;31mHeight.gwas.txt.gz\u001b[0m  sexcheck.R\n",
      "EUR.cov     EUR.QC.hh     EUR.QC.sexcheck   \u001b[01;31mHeight.gz\u001b[0m\n",
      "EUR.fam     EUR.QC.irem   EUR.QC.snplist    \u001b[01;31mHeight.nodup.gz\u001b[0m\n",
      "EUR.height  EUR.QC.log    EUR.QC.valid      \u001b[01;31mHeight.QC.gz\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6dbfe8c1-c116-4412-9945-e74619b95cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HG00096\tHG00096\n",
      "HG00097\tHG00097\n",
      "HG00099\tHG00099\n",
      "HG00101\tHG00101\n",
      "HG00102\tHG00102\n",
      "HG00103\tHG00103\n",
      "HG00105\tHG00105\n",
      "HG00107\tHG00107\n",
      "HG00108\tHG00108\n",
      "HG00109\tHG00109\n",
      " 483  966 7728 EUR.QC.rel.id\n"
     ]
    }
   ],
   "source": [
    "head EUR.QC.rel.id\n",
    "wc EUR.QC.rel.id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a21efa-cd00-44cb-bd09-72d5ea254fce",
   "metadata": {},
   "source": [
    ">A greedy algorithm is used to remove closely related individuals in a way that optimizes the size of the sample retained. However, the algorithm is dependent on the random seed used, which can generate different results. Therefore, to reproduce the same result, you will need to specify the same random seed.\n",
    ">\r",
    ">貪欲なアルゴリズムは、保持されるサンプルのサイズを最適化する方法で、近縁の個体を除去するために使用される。しかし、このアルゴリズムは使用するランダムシードに依存し、異なる結果を生成することがあります。したがって、同じ結果を再現するには、同じランダム・シードを指定する必要があります。\n",
    "\n",
    ">PLINK's algorithm for removing related individuals does not account for the phenotype under study. To minimize the removal of cases of a disease, the following algorithm can be used instead: GreedyRelated.\n",
    ">\n",
    ">近縁個体を除去するPLINKのアルゴリズムは、調査対象の表現型を考慮していません。病気のケースの除去を最小にするために、代わりに以下のアルゴリズムを使用できます： GreedyRelated.le"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0e7ef3-d80e-4fb2-aa8e-139720be1f13",
   "metadata": {},
   "source": [
    "### Generate final QC'ed target data file\n",
    "After performing the full analysis, you can generate a QC'ed data set with the following command:\n",
    "\n",
    "完全な分析を行った後、以下のコマンドでQCされたデータセットを生成することができる："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c7d3a963-925e-43e3-b101-9f670094917d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLINK v1.90b7 64-bit (16 Jan 2023)             www.cog-genomics.org/plink/1.9/\n",
      "(C) 2005-2023 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to EUR.QC.log.\n",
      "Options in effect:\n",
      "  --a1-allele EUR.a1\n",
      "  --bfile EUR\n",
      "  --exclude EUR.mismatch\n",
      "  --extract EUR.QC.snplist\n",
      "  --keep EUR.QC.rel.id\n",
      "  --make-bed\n",
      "  --out EUR.QC\n",
      "\n",
      "257564 MB RAM detected; reserving 128782 MB for main workspace.\n",
      "551892 variants loaded from .bim file.\n",
      "503 people (240 males, 263 females) loaded from .fam.\n",
      "--extract: 540534 variants remaining.\n",
      "--exclude: 489805 variants remaining.\n",
      "--keep: 483 people remaining.\n",
      "Using 1 thread (no multithreaded calculations invoked).\n",
      "Before main variant filters, 483 founders and 0 nonfounders present.\n",
      "Calculating allele frequencies... 10111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989 done.\n",
      "Total genotyping rate in remaining samples is exactly 1.\n",
      "--a1-allele: 489805 assignments made.\n",
      "489805 variants and 483 people pass filters and QC.\n",
      "Note: No phenotypes present.\n",
      "--make-bed to EUR.QC.bed + EUR.QC.bim + EUR.QC.fam ... 101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899done.\n"
     ]
    }
   ],
   "source": [
    "plink \\\n",
    "    --bfile EUR \\\n",
    "    --make-bed \\\n",
    "    --keep EUR.QC.rel.id \\\n",
    "    --out EUR.QC \\\n",
    "    --extract EUR.QC.snplist \\\n",
    "    --exclude EUR.mismatch \\\n",
    "    --a1-allele EUR.a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6997862b-bc93-4b37-8c38-7440ee997f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EUR.a1      EUR.mismatch  EUR.QC.irem       EUR.QC.snplist      \u001b[0m\u001b[01;31mHeight.nodup.gz\u001b[0m\n",
      "EUR.bed     EUR.QC.bed    EUR.QC.log        EUR.QC.valid        \u001b[01;31mHeight.QC.gz\u001b[0m\n",
      "EUR.bim     EUR.QC.bim    EUR.QC.prune.in   EUR.valid.sample    het.R\n",
      "EUR.cov     EUR.QC.fam    EUR.QC.prune.out  \u001b[01;31mEUR.zip\u001b[0m             mismatchSNP.R\n",
      "EUR.fam     EUR.QC.het    EUR.QC.rel.id     \u001b[01;31mHeight.gwas.txt.gz\u001b[0m  sexcheck.R\n",
      "EUR.height  EUR.QC.hh     EUR.QC.sexcheck   \u001b[01;31mHeight.gz\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84338c4-229e-4ed5-a956-f8a32e38436e",
   "metadata": {},
   "source": [
    "## 3. Calculating and Analysing PRS\n",
    "\n",
    "### Background\n",
    "In this section of the tutorial you will use four different software programs to compute PRS from the base and target data that you QC'ed in the previous two sections.\n",
    "\n",
    "-> PLINK PRSice-2 ~~LDpred-2~~ ~~lassosum~~\n",
    "\n",
    "### PLINK\n",
    "\n",
    "#### Background\n",
    "On this page, you will compute PRS using the popular genetic analyses tool plink - while plink is not a dedicated PRS software, you can perform every required steps of the C+T approach with plink. This multi-step process is a good way to learn the processes involved in computing PRS, which are typically performed automatically by PRS software.\n",
    "\n",
    "このページでは、人気の遺伝子解析ツールplinkを使ってPRSを計算します。plinkはPRS専用のソフトウェアではありませんが、plinkを使ってC+Tアプローチの必要なステップをすべて実行できます。この多段階のプロセスは、PRSソフトウェアが通常自動的に行うPRSの計算に関わるプロセスを学ぶ良い方法です。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdc8be8-b3a2-474e-b920-976fba73df3c",
   "metadata": {},
   "source": [
    "#### Required Data\n",
    "In the previous sections, we have generated the following files:\n",
    "\n",
    "* Height.QC.gz:The post-QCed summary statistic\n",
    "* EUR.QC.bed:The genotype file after performing some basic filtering\n",
    "* EUR.QC.bim:This file contains the SNPs that passed the basic filtering\n",
    "* EUR.QC.fam:This file contains the samples that passed the basic filtering\n",
    "* EUR.height:This file contains the phenotype of the samples\n",
    "* EUR.cov:This file contains the covariates of the samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b2eb75-cdb5-4850-92f7-6107e8eb209f",
   "metadata": {},
   "source": [
    "#### Update Effect Size\n",
    "When the effect size relates to disease risk and is thus given as an odds ratio (OR), rather than BETA (for continuous traits), then the PRS is computed as a product of ORs. To simplify this calculation, we take the natural logarithm of the OR so that the PRS can be computed using summation instead (which can be back-transformed afterwards). We can obtain the transformed summary statistics with R:\n",
    "\n",
    "効果量が疾患リスクに関係し、したがって（連続形質の）BETAではなくオッズ比（OR）として与えられる場合、PRSはORの積として計算される。この計算を単純化するために、我々はORの自然対数を取り、PRSが代わりに合計を用いて計算できるようにする（これは後で逆変換できる）。Rで変換された要約統計量を得ることができる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d0727d8-dc6c-46fd-8319-0ec511b84ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dat <- read.table(gzfile(\"Height.QC.gz\"), header=T)\n",
      "dat$BETA <- log(dat$OR)\n",
      "write.table(dat, \"Height.QC.Transformed\", quote=F, row.names=F)\n"
     ]
    }
   ],
   "source": [
    "cat <<EOL > ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data/updateES.R\n",
    "dat <- read.table(gzfile(\"Height.QC.gz\"), header=T)\n",
    "dat\\$BETA <- log(dat\\$OR)\n",
    "write.table(dat, \"Height.QC.Transformed\", quote=F, row.names=F)\n",
    "EOL\n",
    "cat ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data/updateES.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "994d5b77-a8b6-451b-b619-043a0b8fea2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data/\n",
    "Rscript ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data/updateES.R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103e1d8a-0927-4558-a81b-168b2b55fc3b",
   "metadata": {},
   "source": [
    ">Due to rounding of values, using awk to log transform OR can lead to less accurate results. Therefore, we recommend performing the transformation in R or allow the PRS software to perform the transformation directly.\n",
    ">\n",
    ">値の四捨五入のため、awk を使って OR を対数変換すると正確な結果が得られないことがあります。したがって、R で変換を行うか、PRS ソフトウェアで直接変換を行うことをお勧めします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afe0b6e3-33e5-4cf3-8c0a-aeeaf4963b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHR BP SNP A1 A2 N SE P OR INFO MAF BETA\n",
      "1 756604 rs3131962 A G 388028 0.00301666 0.483171 0.997886915712657 0.890557941364774 0.369389592764921 -0.00211532000000048\n",
      "1 768448 rs12562034 A G 388028 0.00329472 0.834808 1.00068731609353 0.895893511351165 0.336845754096289 0.000687079999998082\n",
      "1 779322 rs4040617 G A 388028 0.00303344 0.42897 0.997603556067569 0.897508290615237 0.377368010940814 -0.00239932000000021\n",
      "1 801536 rs79373928 G T 388028 0.00841324 0.808999 1.00203569922793 0.908962856432993 0.483212245374095 0.00203362999999797\n",
      "1 808631 rs11240779 G A 388028 0.00242821 0.590265 1.00130832511154 0.893212523690488 0.450409558999587 0.00130747000000259\n",
      "1 809876 rs57181708 G A 388028 0.00336785 0.71475 1.00123165786833 0.923557624081969 0.499743932656759 0.00123090000000354\n",
      "1 835499 rs4422948 G A 388028 0.0023758 0.710884 0.999119752645202 0.906437735120596 0.481016005816168 -0.000880634999999921\n",
      "1 838555 rs4970383 A C 388028 0.00235773 0.150993 0.996619945289758 0.907716506801574 0.327164029672754 -0.0033857799999997\n",
      "1 840753 rs4970382 C T 388028 0.00207377 0.199967 0.99734567895614 0.914602590137255 0.498936220426316 -0.00265785000000019\n"
     ]
    }
   ],
   "source": [
    "head Height.QC.Transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfac058-fb5b-4fb8-9d52-63bb0384463b",
   "metadata": {},
   "source": [
    "#### Clumping\n",
    "Linkage disequilibrium, which corresponds to the correlation between the genotypes of genetic variants across the genome, makes identifying the contribution from causal independent genetic variants extremely challenging. One way of approximately capturing the right level of causal signal is to perform clumping, which removes SNPs in ways that only weakly correlated SNPs are retained but preferentially retaining the SNPs most associated with the phenotype under study. Clumping can be performed using the following command in plink:\n",
    "\n",
    "連鎖不平衡は、ゲノム全体の遺伝的変異の遺伝子型間の相関に相当し、原因となる独立した遺伝的変異からの寄与を同定することを非常に困難にしている。これは、相関の弱いSNPのみを残し、研究対象の表現型と最も関連するSNPを優先的に残すようにSNPを除去する方法である。クランピングはplinkの以下のコマンドで実行できる："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3c682f9-a2cc-4b54-9178-92b290bbf79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLINK v1.90b7 64-bit (16 Jan 2023)             www.cog-genomics.org/plink/1.9/\n",
      "(C) 2005-2023 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to EUR.log.\n",
      "Options in effect:\n",
      "  --bfile EUR.QC\n",
      "  --clump Height.QC.Transformed\n",
      "  --clump-field P\n",
      "  --clump-kb 250\n",
      "  --clump-p1 1\n",
      "  --clump-r2 0.1\n",
      "  --clump-snp-field SNP\n",
      "  --out EUR\n",
      "\n",
      "257564 MB RAM detected; reserving 128782 MB for main workspace.\n",
      "489805 variants loaded from .bim file.\n",
      "483 people (232 males, 251 females) loaded from .fam.\n",
      "Using 1 thread (no multithreaded calculations invoked).\n",
      "Before main variant filters, 483 founders and 0 nonfounders present.\n",
      "Calculating allele frequencies... 10111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989 done.\n",
      "Total genotyping rate is exactly 1.\n",
      "489805 variants and 483 people pass filters and QC.\n",
      "Note: No phenotypes present.\n",
      "Warning: 'rs1076829' is missing from the main dataset, and is a top variant.\n",
      "Warning: 'rs3129818' is missing from the main dataset, and is a top variant.\n",
      "Warning: 'rs3118359' is missing from the main dataset, and is a top variant.\n",
      "9809 more top variant IDs missing; see log file.\n",
      "--clump: 193758 clumps formed from 489805 top variants.\n",
      "Results written to EUR.clumped .\n"
     ]
    }
   ],
   "source": [
    "plink \\\n",
    "    --bfile EUR.QC \\\n",
    "    --clump-p1 1 \\\n",
    "    --clump-r2 0.1 \\\n",
    "    --clump-kb 250 \\\n",
    "    --clump Height.QC.Transformed \\\n",
    "    --clump-snp-field SNP \\\n",
    "    --clump-field P \\\n",
    "    --out EUR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26353b79-7fca-4f92-a52d-1c5821b66a6f",
   "metadata": {},
   "source": [
    "* clump-p1:P-value threshold for a SNP to be included as an index SNP. 1 is selected such that all SNPs are include for clumping\n",
    "* clump-r2:SNPs having r2 higher than 0.1 with the index SNPs will be removed\n",
    "* clump-kb:SNPs within 250k of the index SNP are considered for clumping\n",
    "* clump:Base data (summary statistic) file containing the P-value information\n",
    "* clump-snp-field:Specifies that the column SNP contains the SNP IDs\n",
    "* clump-field:Specifies that the column P contains the P-value information\n",
    "\n",
    ">The r2 values computed by --clump are based on maximum likelihood haplotype frequency estimates\n",
    ">\n",
    ">--clumpによって計算されたr2値は、最尤ハプロタイプ頻度推定値に基づいている。\n",
    "\n",
    "This will generate EUR.clumped, containing the index SNPs after clumping is performed. We can extract the index SNP ID by performing the following command:\n",
    "\n",
    "これにより、クランピング後のインデックス SNP を含む EUR.clumped が生成される。以下のコマンドを実行することで、インデックス SNP ID を抽出することができます："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9adc407e-58ee-4d9a-b329-11753dddcfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "awk 'NR!=1{print $3}' EUR.clumped >  EUR.valid.snp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48001c0f-4812-4bc7-9927-4e993db89086",
   "metadata": {},
   "source": [
    "\\$3 because the third column contains the SNP ID\n",
    "\n",
    ">If your target data are small (e.g. N < 500) then you can use the 1000 Genomes Project samples for the LD calculation. Make sure to use the population that most closely reflects represents the base sample.\n",
    ">\n",
    ">対象データが小さい場合（例えばN < 500）、1000 Genomes ProjectのサンプルをLD計算に使用することができます。必ずベースサンプルを最もよく反映する母集団を使用してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89586a6-44fb-4891-9fb6-675aaf3fd514",
   "metadata": {},
   "source": [
    "#### Generate PRS\n",
    "\n",
    "plink provides a convenient function --score and --q-score-range for calculating polygenic scores.\n",
    "\n",
    "plinkには多遺伝子スコアを計算する便利な関数-scoreと--q-score-rangeがある。\n",
    "\n",
    "We will need three files:\n",
    "\n",
    "1. The base data file: Height.QC.Transformed\n",
    "2. A file containing SNP IDs and their corresponding P-values\n",
    "   * \\$3 because SNP ID is located in the third column\n",
    "   * \\$8 because the P-value is located in the eighth column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aee0963f-b8ed-43d2-81ef-63b5118a144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "awk '{print $3,$8}' Height.QC.Transformed > SNP.pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afbc769-e1e2-4135-b39b-ffa9a9fa0a39",
   "metadata": {},
   "source": [
    "3. A file containing the different P-value thresholds for inclusion of SNPs in the PRS. Here calculate PRS corresponding to a few thresholds for illustration purposes:\n",
    "\n",
    "   PRSにSNPを含めるための様々なP値の閾値を含むファイル。ここでは説明のためにいくつかの閾値に対応するPRSを計算する："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "386fe370-9f7a-42d1-8c5e-a782ed74cb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "echo \"0.001 0 0.001\" > range_list \n",
    "echo \"0.05 0 0.05\" >> range_list\n",
    "echo \"0.1 0 0.1\" >> range_list\n",
    "echo \"0.2 0 0.2\" >> range_list\n",
    "echo \"0.3 0 0.3\" >> range_list\n",
    "echo \"0.4 0 0.4\" >> range_list\n",
    "echo \"0.5 0 0.5\" >> range_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06d1d1f-6554-4e28-b36f-a6ca1e158ddc",
   "metadata": {},
   "source": [
    "The format of the range_list file should be as follows:Name of Threshold/Lower bound/Upper Bound\n",
    "\n",
    ">The threshold boundaries are inclusive. For example, for the 0.05 threshold, we include all SNPs with P-value from 0 to 0.05, including any SNPs with P-value equal to 0.05.\n",
    ">\n",
    ">閾値の境界は包括的である。例えば、0.05の閾値の場合、P値が0から0.05のすべてのSNPを含み、P値が0.05に等しいSNPも含む。\n",
    "\n",
    "We can then calculate the PRS with the following plink command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9762a567-2fe8-4c2c-b7b9-9f5fc378e1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLINK v1.90b7 64-bit (16 Jan 2023)             www.cog-genomics.org/plink/1.9/\n",
      "(C) 2005-2023 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to EUR.log.\n",
      "Options in effect:\n",
      "  --bfile EUR.QC\n",
      "  --extract EUR.valid.snp\n",
      "  --out EUR\n",
      "  --q-score-range range_list SNP.pvalue\n",
      "  --score Height.QC.Transformed 3 4 12 header\n",
      "\n",
      "257564 MB RAM detected; reserving 128782 MB for main workspace.\n",
      "489805 variants loaded from .bim file.\n",
      "483 people (232 males, 251 females) loaded from .fam.\n",
      "--extract: 193758 variants remaining.\n",
      "Using 1 thread (no multithreaded calculations invoked).\n",
      "Before main variant filters, 483 founders and 0 nonfounders present.\n",
      "Calculating allele frequencies... 10111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989 done.\n",
      "Total genotyping rate is exactly 1.\n",
      "193758 variants and 483 people pass filters and QC.\n",
      "Note: No phenotypes present.\n",
      "Warning: 305859 lines skipped in --score file (305859 due to variant ID\n",
      "mismatch, 0 due to allele code mismatch); see EUR.nopred for details.\n",
      "--score: 193758 valid predictors loaded.\n",
      "Warning: 305860 lines skipped in --q-score-range data file.\n",
      "--score: 7 ranges processed.\n",
      "Results written to EUR.*.profile.\n"
     ]
    }
   ],
   "source": [
    "plink \\\n",
    "    --bfile EUR.QC \\\n",
    "    --score Height.QC.Transformed 3 4 12 header \\\n",
    "    --q-score-range range_list SNP.pvalue \\\n",
    "    --extract EUR.valid.snp \\\n",
    "    --out EUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39380b5b-430f-4b7e-bd90-065d81cefa8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 hmiwa hmiwa 25691 11月 13 14:18 EUR.0.001.profile\n",
      "-rw-rw-r-- 1 hmiwa hmiwa 25731 11月 13 14:18 EUR.0.05.profile\n",
      "-rw-rw-r-- 1 hmiwa hmiwa 25713 11月 13 14:18 EUR.0.1.profile\n",
      "-rw-rw-r-- 1 hmiwa hmiwa 25703 11月 13 14:18 EUR.0.2.profile\n",
      "-rw-rw-r-- 1 hmiwa hmiwa 25693 11月 13 14:18 EUR.0.3.profile\n",
      "-rw-rw-r-- 1 hmiwa hmiwa 25701 11月 13 14:18 EUR.0.4.profile\n",
      "-rw-rw-r-- 1 hmiwa hmiwa 25672 11月 13 14:19 EUR.0.5.profile\n"
     ]
    }
   ],
   "source": [
    "ls -l *.profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b246ccf4-9051-4d3a-9313-d775769da7d8",
   "metadata": {},
   "source": [
    "#### Accounting for Population Stratification\r\n",
    "\r\n",
    "Population structure is the principal source of confounding in GWAS and is usually accounted for by incorporating principal components (PCs) as covariates. We can incorporate PCs into our PRS analysis to account for population stratification.\r\n",
    "\r\n",
    "集団構造はGWASにおける交絡の主要な原因であり、通常は共変量として主成分（PC）を組み込むことによって説明される。集団の層別化を考慮するために、PRS解析にPCを組み込むことができる。\r\n",
    "\r\n",
    "Again, we can calculate the PCs using plink:\r\n",
    "\r\n",
    "ここでもplinkを使ってPCを計算することができる："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b53d19e-0212-4951-9b0a-30a684de55a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLINK v1.90b7 64-bit (16 Jan 2023)             www.cog-genomics.org/plink/1.9/\n",
      "(C) 2005-2023 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to EUR.log.\n",
      "Options in effect:\n",
      "  --bfile EUR.QC\n",
      "  --indep-pairwise 200 50 0.25\n",
      "  --out EUR\n",
      "\n",
      "257564 MB RAM detected; reserving 128782 MB for main workspace.\n",
      "489805 variants loaded from .bim file.\n",
      "483 people (232 males, 251 females) loaded from .fam.\n",
      "Using 1 thread (no multithreaded calculations invoked).\n",
      "Before main variant filters, 483 founders and 0 nonfounders present.\n",
      "Calculating allele frequencies... 10111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989 done.\n",
      "Total genotyping rate is exactly 1.\n",
      "489805 variants and 483 people pass filters and QC.\n",
      "Note: No phenotypes present.\n",
      "Pruned 18635 variants from chromosome 1, leaving 20449.\n",
      "Pruned 19319 variants from chromosome 2, leaving 20251.\n",
      "Pruned 16145 variants from chromosome 3, leaving 17177.\n",
      "Pruned 15167 variants from chromosome 4, leaving 16141.\n",
      "Pruned 13994 variants from chromosome 5, leaving 15446.\n",
      "Pruned 19041 variants from chromosome 6, leaving 14943.\n",
      "Pruned 12882 variants from chromosome 7, leaving 14119.\n",
      "Pruned 12195 variants from chromosome 8, leaving 13100.\n",
      "Pruned 9844 variants from chromosome 9, leaving 11496.\n",
      "Pruned 11825 variants from chromosome 10, leaving 12923.\n",
      "Pruned 11986 variants from chromosome 11, leaving 12286.\n",
      "Pruned 10802 variants from chromosome 12, leaving 12107.\n",
      "Pruned 7824 variants from chromosome 13, leaving 9296.\n",
      "Pruned 7508 variants from chromosome 14, leaving 8478.\n",
      "Pruned 7251 variants from chromosome 15, leaving 8203.\n",
      "Pruned 7900 variants from chromosome 16, leaving 9012.\n",
      "Pruned 7344 variants from chromosome 17, leaving 8410.\n",
      "Pruned 6654 variants from chromosome 18, leaving 8298.\n",
      "Pruned 6347 variants from chromosome 19, leaving 6472.\n",
      "Pruned 5862 variants from chromosome 20, leaving 7282.\n",
      "Pruned 3373 variants from chromosome 21, leaving 4124.\n",
      "Pruned 3720 variants from chromosome 22, leaving 4174.\n",
      "Pruning complete.  235618 of 489805 variants removed.\n",
      "Marker lists written to EUR.prune.in and EUR.prune.out .\n",
      "PLINK v1.90b7 64-bit (16 Jan 2023)             www.cog-genomics.org/plink/1.9/\n",
      "(C) 2005-2023 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to EUR.log.\n",
      "Options in effect:\n",
      "  --bfile EUR.QC\n",
      "  --extract EUR.prune.in\n",
      "  --out EUR\n",
      "  --pca 6\n",
      "\n",
      "257564 MB RAM detected; reserving 128782 MB for main workspace.\n",
      "489805 variants loaded from .bim file.\n",
      "483 people (232 males, 251 females) loaded from .fam.\n",
      "--extract: 254187 variants remaining.\n",
      "Using up to 63 threads (change this with --threads).\n",
      "Before main variant filters, 483 founders and 0 nonfounders present.\n",
      "Calculating allele frequencies... 10111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989 done.\n",
      "Total genotyping rate is exactly 1.\n",
      "254187 variants and 483 people pass filters and QC.\n",
      "Note: No phenotypes present.\n",
      "41460 markers complete.\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relationship matrix calculation complete.\n",
      "--pca: Results saved to EUR.eigenval and EUR.eigenvec .\n"
     ]
    }
   ],
   "source": [
    "# First, we need to perform prunning\n",
    "plink \\\n",
    "    --bfile EUR.QC \\\n",
    "    --indep-pairwise 200 50 0.25 \\\n",
    "    --out EUR\n",
    "# Then we calculate the first 6 PCs\n",
    "plink \\\n",
    "    --bfile EUR.QC \\\n",
    "    --extract EUR.prune.in \\\n",
    "    --pca 6 \\\n",
    "    --out EUR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c82764-ce51-4f48-8e3d-9b03664cf1f5",
   "metadata": {},
   "source": [
    ">One way to select the appropriate number of PCs is to perform GWAS on the phenotype under study with different numbers of PCs. LDSC analysis can then be performed on the set of GWAS summary statistics and the GWAS that used the number of PCs that gave an LDSC intercept closest to 1 should correspond to that for which population structure was most accurately controlled for.\n",
    ">\n",
    ">適切なPC数を選択する1つの方法は、研究対象の表現型について異なるPC数でGWASを実施することである。LDSC解析はGWASの要約統計量のセットで行うことができ、LDSCの切片が1に最も近くなるPC数を用いたGWASは、集団構造が最も正確にコントロールされたものに対応するはずである。\n",
    "\n",
    "Here the PCs have been stored in the EUR.eigenvec file and can be used as covariates in the regression model to account for population stratification.\n",
    "\n",
    "ここでPCはEUR.eigenvecファイルに格納されており、母集団の層別化を考慮する回帰モデルの共変量として使用することができる。\n",
    "\n",
    ">If the base and target samples are collected from different worldwide populations then the results from the PRS analysis may be biased (see Section 3.4 of our paper).\n",
    ">\n",
    ">ベースサンプルとターゲットサンプルが異なる世界中の集団から収集された場合、PRS分析の結果に偏りが生じる可能性があります（論文セクション3.4参照）。\n",
    "\n",
    "#### Finding the \"best-fit\" PRS\n",
    "The P-value threshold that provides the \"best-fit\" PRS under the C+T method is usually unknown. To approximate the \"best-fit\" PRS, we can perform a regression between PRS calculated at a range of P-value thresholds and then select the PRS that explains the highest phenotypic variance (please see Section 4.6 of our paper on overfitting issues). This can be achieved using R as follows:\n",
    "\n",
    "C+T法で \"ベストフィット \"PRSを提供するP値のしきい値は，通常不明である．ベスト・フィット」PRSを近似するには，さまざまなP値のしきい値で計算されたPRSの間で回帰を行い，表現型の分散を最もよく説明するPRSを選ぶことができる（オーバーフィッティングの問題については，我々の論文の4.6節を参照）．これはRを用いて次のように行うことができます："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f8f18c2-cac7-4317-9214-e73f91877cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p.threshold <- c(0.001,0.05,0.1,0.2,0.3,0.4,0.5)\n",
      "# Read in the phenotype file \n",
      "phenotype <- read.table(\"EUR.height\", header=T)\n",
      "# Read in the PCs\n",
      "pcs <- read.table(\"EUR.eigenvec\", header=F)\n",
      "# The default output from plink does not include a header\n",
      "# To make things simple, we will add the appropriate headers\n",
      "# (1:6 because there are 6 PCs)\n",
      "colnames(pcs) <- c(\"FID\", \"IID\", paste0(\"PC\",1:6)) \n",
      "# Read in the covariates (here, it is sex)\n",
      "covariate <- read.table(\"EUR.cov\", header=T)\n",
      "# Now merge the files\n",
      "pheno <- merge(merge(phenotype, covariate, by=c(\"FID\", \"IID\")), pcs, by=c(\"FID\",\"IID\"))\n",
      "# We can then calculate the null model (model with PRS) using a linear regression \n",
      "# (as height is quantitative)\n",
      "null.model <- lm(Height~., data=pheno[,!colnames(pheno)%in%c(\"FID\",\"IID\")])\n",
      "# And the R2 of the null model is \n",
      "null.r2 <- summary(null.model)$r.squared\n",
      "prs.result <- NULL\n",
      "for(i in p.threshold){\n",
      "    # Go through each p-value threshold\n",
      "    prs <- read.table(paste0(\"EUR.\",i,\".profile\"), header=T)\n",
      "    # Merge the prs with the phenotype matrix\n",
      "    # We only want the FID, IID and PRS from the PRS file, therefore we only select the \n",
      "    # relevant columns\n",
      "    pheno.prs <- merge(pheno, prs[,c(\"FID\",\"IID\", \"SCORE\")], by=c(\"FID\", \"IID\"))\n",
      "    # Now perform a linear regression on Height with PRS and the covariates\n",
      "    # ignoring the FID and IID from our model\n",
      "    model <- lm(Height~., data=pheno.prs[,!colnames(pheno.prs)%in%c(\"FID\",\"IID\")])\n",
      "    # model R2 is obtained as \n",
      "    model.r2 <- summary(model)$r.squared\n",
      "    # R2 of PRS is simply calculated as the model R2 minus the null R2\n",
      "    prs.r2 <- model.r2-null.r2\n",
      "    # We can also obtain the coeffcient and p-value of association of PRS as follow\n",
      "    prs.coef <- summary(model)$coeff[\"SCORE\",]\n",
      "    prs.beta <- as.numeric(prs.coef[1])\n",
      "    prs.se <- as.numeric(prs.coef[2])\n",
      "    prs.p <- as.numeric(prs.coef[4])\n",
      "    # We can then store the results\n",
      "    prs.result <- rbind(prs.result, data.frame(Threshold=i, R2=prs.r2, P=prs.p, BETA=prs.beta,SE=prs.se))\n",
      "}\n",
      "# Best result is:\n",
      "prs.result[which.max(prs.result$R2),]\n"
     ]
    }
   ],
   "source": [
    "cat <<EOL > ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data/BFPRS.R\n",
    "p.threshold <- c(0.001,0.05,0.1,0.2,0.3,0.4,0.5)\n",
    "# Read in the phenotype file \n",
    "phenotype <- read.table(\"EUR.height\", header=T)\n",
    "# Read in the PCs\n",
    "pcs <- read.table(\"EUR.eigenvec\", header=F)\n",
    "# The default output from plink does not include a header\n",
    "# To make things simple, we will add the appropriate headers\n",
    "# (1:6 because there are 6 PCs)\n",
    "colnames(pcs) <- c(\"FID\", \"IID\", paste0(\"PC\",1:6)) \n",
    "# Read in the covariates (here, it is sex)\n",
    "covariate <- read.table(\"EUR.cov\", header=T)\n",
    "# Now merge the files\n",
    "pheno <- merge(merge(phenotype, covariate, by=c(\"FID\", \"IID\")), pcs, by=c(\"FID\",\"IID\"))\n",
    "# We can then calculate the null model (model with PRS) using a linear regression \n",
    "# (as height is quantitative)\n",
    "null.model <- lm(Height~., data=pheno[,!colnames(pheno)%in%c(\"FID\",\"IID\")])\n",
    "# And the R2 of the null model is \n",
    "null.r2 <- summary(null.model)\\$r.squared\n",
    "prs.result <- NULL\n",
    "for(i in p.threshold){\n",
    "    # Go through each p-value threshold\n",
    "    prs <- read.table(paste0(\"EUR.\",i,\".profile\"), header=T)\n",
    "    # Merge the prs with the phenotype matrix\n",
    "    # We only want the FID, IID and PRS from the PRS file, therefore we only select the \n",
    "    # relevant columns\n",
    "    pheno.prs <- merge(pheno, prs[,c(\"FID\",\"IID\", \"SCORE\")], by=c(\"FID\", \"IID\"))\n",
    "    # Now perform a linear regression on Height with PRS and the covariates\n",
    "    # ignoring the FID and IID from our model\n",
    "    model <- lm(Height~., data=pheno.prs[,!colnames(pheno.prs)%in%c(\"FID\",\"IID\")])\n",
    "    # model R2 is obtained as \n",
    "    model.r2 <- summary(model)\\$r.squared\n",
    "    # R2 of PRS is simply calculated as the model R2 minus the null R2\n",
    "    prs.r2 <- model.r2-null.r2\n",
    "    # We can also obtain the coeffcient and p-value of association of PRS as follow\n",
    "    prs.coef <- summary(model)\\$coeff[\"SCORE\",]\n",
    "    prs.beta <- as.numeric(prs.coef[1])\n",
    "    prs.se <- as.numeric(prs.coef[2])\n",
    "    prs.p <- as.numeric(prs.coef[4])\n",
    "    # We can then store the results\n",
    "    prs.result <- rbind(prs.result, data.frame(Threshold=i, R2=prs.r2, P=prs.p, BETA=prs.beta,SE=prs.se))\n",
    "}\n",
    "# Best result is:\n",
    "prs.result[which.max(prs.result\\$R2),]\n",
    "EOL\n",
    "cat ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data/BFPRS.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ffa6781-8244-4490-bc83-887fb92e8324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Threshold        R2           P     BETA       SE\n",
      "5       0.3 0.1612372 2.77407e-25 45316.19 4107.777\n"
     ]
    }
   ],
   "source": [
    "Rscript ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data/BFPRS.R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4b0f68-5f96-4800-a7f8-a234437f8442",
   "metadata": {},
   "source": [
    "* Which P-value threshold generates the \"best-fit\" PRS? -> Threshold\n",
    "* How much phenotypic variation does the \"best-fit\" PRS explain? -> R2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018b6dcf-d8b7-4947-880f-6cbaf465572a",
   "metadata": {},
   "source": [
    "### PRSice-2\n",
    "\n",
    "#### Background\n",
    "PRSice-2 is one of the dedicated PRS programs which automates many of the steps from the previous page that used a sequence of PLINK functions (plus some QC steps). On this page you will run a PRS analysis using PRSice-2, which implements the standard C+T method.\n",
    "\n",
    "PRSice-2はPRS専用プログラムの1つで、PLINK関数のシーケンスを使用した前ページのステップの多く（およびいくつかのQCステップ）を自動化します。このページでは、標準的なC+T法を実装したPRSice-2を使用してPRS解析を実行します。\n",
    "\n",
    "#### Obtaining PRSice-2\n",
    "PRSice-2 can be downloaded from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04f8a02e-566f-43a6-b151-c5ce330079f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-11-13 15:28:25--  https://github.com/choishingwan/PRSice/releases/download/2.3.3/PRSice_linux.zip\n",
      "Resolving github.com (github.com)... 20.27.177.113\n",
      "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/64860041/1e8b8800-d714-11ea-830f-cf872a4c01fe?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231113%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231113T062825Z&X-Amz-Expires=300&X-Amz-Signature=4d6581d1b0d4e4ed4883653cbd323e30265dbf56e3c83651e1ad241c6426c3fd&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=64860041&response-content-disposition=attachment%3B%20filename%3DPRSice_linux.zip&response-content-type=application%2Foctet-stream [following]\n",
      "--2023-11-13 15:28:25--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/64860041/1e8b8800-d714-11ea-830f-cf872a4c01fe?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231113%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231113T062825Z&X-Amz-Expires=300&X-Amz-Signature=4d6581d1b0d4e4ed4883653cbd323e30265dbf56e3c83651e1ad241c6426c3fd&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=64860041&response-content-disposition=attachment%3B%20filename%3DPRSice_linux.zip&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 33123522 (32M) [application/octet-stream]\n",
      "Saving to: ‘PRSice_linux.zip’\n",
      "\n",
      "PRSice_linux.zip    100%[===================>]  31.59M   110MB/s    in 0.3s    \n",
      "\n",
      "2023-11-13 15:28:26 (110 MB/s) - ‘PRSice_linux.zip’ saved [33123522/33123522]\n",
      "\n",
      "Archive:  PRSice_linux.zip\n",
      "  inflating: PRSice.R                \n",
      "  inflating: TOY_BASE_GWAS.assoc     \n",
      "  inflating: TOY_TARGET_DATA.bed     \n",
      "  inflating: TOY_TARGET_DATA.bim     \n",
      "  inflating: TOY_TARGET_DATA.fam     \n",
      "  inflating: TOY_TARGET_DATA.pheno   \n",
      "  inflating: PRSice_linux            \n",
      "BFPRS.R            EUR.nopred        \u001b[0m\u001b[01;31mHeight.gwas.txt.gz\u001b[0m\n",
      "EUR.0.001.profile  EUR.prune.in      \u001b[01;31mHeight.gz\u001b[0m\n",
      "EUR.0.05.profile   EUR.prune.out     \u001b[01;31mHeight.nodup.gz\u001b[0m\n",
      "EUR.0.1.profile    EUR.QC.bed        \u001b[01;31mHeight.QC.gz\u001b[0m\n",
      "EUR.0.2.profile    EUR.QC.bim        Height.QC.Transformed\n",
      "EUR.0.3.profile    EUR.QC.fam        het.R\n",
      "EUR.0.4.profile    EUR.QC.het        mismatchSNP.R\n",
      "EUR.0.5.profile    EUR.QC.hh         \u001b[01;32mPRSice_linux\u001b[0m\n",
      "EUR.a1             EUR.QC.irem       \u001b[01;31mPRSice_linux.zip\u001b[0m\n",
      "EUR.bed            EUR.QC.log        \u001b[01;32mPRSice.R\u001b[0m\n",
      "EUR.bim            EUR.QC.prune.in   range_list\n",
      "EUR.clumped        EUR.QC.prune.out  sexcheck.R\n",
      "EUR.cov            EUR.QC.rel.id     SNP.pvalue\n",
      "EUR.eigenval       EUR.QC.sexcheck   TOY_BASE_GWAS.assoc\n",
      "EUR.eigenvec       EUR.QC.snplist    TOY_TARGET_DATA.bed\n",
      "EUR.fam            EUR.QC.valid      TOY_TARGET_DATA.bim\n",
      "EUR.height         EUR.valid.sample  TOY_TARGET_DATA.fam\n",
      "EUR.log            EUR.valid.snp     TOY_TARGET_DATA.pheno\n",
      "EUR.mismatch       \u001b[01;31mEUR.zip\u001b[0m           updateES.R\n"
     ]
    }
   ],
   "source": [
    "cd ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data/\n",
    "wget https://github.com/choishingwan/PRSice/releases/download/2.3.3/PRSice_linux.zip\n",
    "unzip PRSice_linux.zip\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57f7819-2216-4b20-bde9-feb888b059fb",
   "metadata": {},
   "source": [
    "In this tutorial, you will only need PRSice.R and PRSice_XXX where XXX is the operation system\n",
    "\n",
    "このチュートリアルでは、PRSice.RとPRSice_XXX（XXXはオペレーションシステム）だけが必要です。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676739f6-d484-4aed-80db-ca308cf7390a",
   "metadata": {},
   "source": [
    "#### Required Data\n",
    "This analysis assumes that you have the following files (or you can download it from here):\n",
    "\n",
    "* Height.QC.gz:The post QC base data file. While PRSice-2 can automatically apply most filtering on the base file, it cannot remove duplicated SNPs\n",
    "* EUR.QC.bed:This file contains the genotype data that passed the QC steps\n",
    "* EUR.QC.bim:This file contains the list of SNPs that passed the QC steps\n",
    "* EUR.QC.fam:This file contains the samples that passed the QC steps\n",
    "* EUR.height:This file contains the phenotype data of the samples\n",
    "* EUR.cov:This file contains the covariates of the samples\n",
    "* EUR.eigenvec:This file contains the principal components (PCs) of the samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689ea67f-6f90-4ee1-83ee-c38a056e8919",
   "metadata": {},
   "source": [
    "#### Running PRS analysis\n",
    "To run PRSice-2 we need a single covariate file, and therefore our covariate file and PCs file should be combined. This can be done with R as follows:\n",
    "\n",
    "PRSice-2を実行するには、1つの共変量ファイルが必要なので、共変量ファイルとPCsファイルを結合する必要があります。これはRで次のように行うことができる："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3e755d06-f351-4b28-9a7c-927b457728db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covariate <- read.table(\"EUR.cov\", header=T)\n",
      "pcs <- read.table(\"EUR.eigenvec\", header=F)\n",
      "colnames(pcs) <- c(\"FID\",\"IID\", paste0(\"PC\",1:6))\n",
      "cov <- merge(covariate, pcs, by=c(\"FID\", \"IID\"))\n",
      "write.table(cov,\"EUR.covariate\", quote=F, row.names=F)\n"
     ]
    }
   ],
   "source": [
    "cat <<EOL > ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data/PRSgetpc.R\n",
    "covariate <- read.table(\"EUR.cov\", header=T)\n",
    "pcs <- read.table(\"EUR.eigenvec\", header=F)\n",
    "colnames(pcs) <- c(\"FID\",\"IID\", paste0(\"PC\",1:6))\n",
    "cov <- merge(covariate, pcs, by=c(\"FID\", \"IID\"))\n",
    "write.table(cov,\"EUR.covariate\", quote=F, row.names=F)\n",
    "EOL\n",
    "cat ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data/PRSgetpc.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c59b5637-c5e6-4262-8b77-4c1cb9c0d69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data/\n",
    "Rscript ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data/PRSgetpc.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c66286d1-ecf8-4087-b29d-a863ab5660a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFPRS.R                           EUR.mismatch      \u001b[0m\u001b[01;31mHeight.gwas.txt.gz\u001b[0m\n",
      "EUR.0.001.profile                 EUR.nopred        \u001b[01;31mHeight.gz\u001b[0m\n",
      "EUR.0.05.profile                  EUR.prsice        \u001b[01;31mHeight.nodup.gz\u001b[0m\n",
      "EUR.0.1.profile                   EUR.prune.in      \u001b[01;31mHeight.QC.gz\u001b[0m\n",
      "EUR.0.2.profile                   EUR.prune.out     Height.QC.Transformed\n",
      "EUR.0.3.profile                   EUR.QC.bed        het.R\n",
      "EUR.0.4.profile                   EUR.QC.bim        \u001b[01;34mlib\u001b[0m\n",
      "EUR.0.5.profile                   EUR.QC.fam        mismatchSNP.R\n",
      "EUR.a1                            EUR.QC.het        PRSgetpc.R\n",
      "\u001b[01;35mEUR_BARPLOT_2023-11-13.png\u001b[0m        EUR.QC.hh         \u001b[01;32mPRSice_linux\u001b[0m\n",
      "EUR.bed                           EUR.QC.irem       \u001b[01;31mPRSice_linux.zip\u001b[0m\n",
      "EUR.best                          EUR.QC.log        \u001b[01;32mPRSice.R\u001b[0m\n",
      "EUR.bim                           EUR.QC.prune.in   range_list\n",
      "EUR.clumped                       EUR.QC.prune.out  sexcheck.R\n",
      "EUR.cov                           EUR.QC.rel.id     SNP.pvalue\n",
      "EUR.covariate                     EUR.QC.sexcheck   TOY_BASE_GWAS.assoc\n",
      "EUR.eigenval                      EUR.QC.snplist    TOY_TARGET_DATA.bed\n",
      "EUR.eigenvec                      EUR.QC.valid      TOY_TARGET_DATA.bim\n",
      "EUR.fam                           EUR.summary       TOY_TARGET_DATA.fam\n",
      "EUR.height                        EUR.valid.sample  TOY_TARGET_DATA.pheno\n",
      "\u001b[01;35mEUR_HIGH-RES_PLOT_2023-11-13.png\u001b[0m  EUR.valid.snp     updateES.R\n",
      "EUR.log                           \u001b[01;31mEUR.zip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7f74c4-9421-4a7e-a2ee-48d227e5c8de",
   "metadata": {},
   "source": [
    "PRSice-2 can then be run to obtain the PRS results as follows:\n",
    "\n",
    "PRSice-2を実行すると、次のようにPRSの結果を得ることができる："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cb93f2e4-ea1f-4829-8793-04cb0ce91fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25hPRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2023-11-13 15:49:56\n",
      "./PRSice_linux \\\n",
      "    --a1 A1 \\\n",
      "    --a2 A2 \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base Height.QC.gz \\\n",
      "    --base-info INFO:0.8 \\\n",
      "    --base-maf MAF:0.01 \\\n",
      "    --binary-target F \\\n",
      "    --bp BP \\\n",
      "    --chr CHR \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov EUR.covariate \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --or  \\\n",
      "    --out EUR \\\n",
      "    --pheno EUR.height \\\n",
      "    --pvalue P \\\n",
      "    --seed 3154700390 \\\n",
      "    --snp SNP \\\n",
      "    --stat OR \\\n",
      "    --target EUR.QC \\\n",
      "    --thread 1 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: EUR.QC (bed) \n",
      "\n",
      "Start processing Height.QC \n",
      "================================================== \n",
      "\n",
      "Base file: Height.QC.gz \n",
      "GZ file detected. Header of file is: \n",
      "CHR\tBP\tSNP\tA1\tA2\tN\tSE\tP\tOR\tINFO\tMAF \n",
      "\n",
      "Reading 100.00%\n",
      "499617 variant(s) observed in base file, with: \n",
      "499617 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "483 people (232 male(s), 251 female(s)) observed \n",
      "483 founder(s) included \n",
      "\n",
      "489805 variant(s) included \n",
      "\n",
      "Phenotype file: EUR.height \n",
      "Column Name of Sample ID: FID+IID \n",
      "Note: If the phenotype file does not contain a header, the \n",
      "column name will be displayed as the Sample ID which is \n",
      "expected. \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 29.88%\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the 1 th phenotype \n",
      "\n",
      "Height is a continuous phenotype \n",
      "11 sample(s) without phenotype \n",
      "472 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: EUR.covariate \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "Sex\t0\t- \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "\n",
      "After reading the covariate file, 472 sample(s) included in \n",
      "the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 29.75%\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting the high resolution plot\n",
      "\u001b[?25h\u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "Rscript PRSice.R \\\n",
    "    --prsice PRSice_linux \\\n",
    "    --base Height.QC.gz \\\n",
    "    --target EUR.QC \\\n",
    "    --binary-target F \\\n",
    "    --pheno EUR.height \\\n",
    "    --cov EUR.covariate \\\n",
    "    --base-maf MAF:0.01 \\\n",
    "    --base-info INFO:0.8 \\\n",
    "    --stat OR \\\n",
    "    --or \\\n",
    "    --out EUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c16be9d4-2e86-4023-8857-81b6ca528cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 hmiwa hmiwa    25691 11月 13 14:18 EUR.0.001.profile\n",
      "-rw-rw-r-- 1 hmiwa hmiwa    25731 11月 13 14:18 EUR.0.05.profile\n",
      "-rw-rw-r-- 1 hmiwa hmiwa    25713 11月 13 14:18 EUR.0.1.profile\n",
      "-rw-rw-r-- 1 hmiwa hmiwa    25703 11月 13 14:18 EUR.0.2.profile\n",
      "-rw-rw-r-- 1 hmiwa hmiwa    25693 11月 13 14:18 EUR.0.3.profile\n",
      "-rw-rw-r-- 1 hmiwa hmiwa    25701 11月 13 14:18 EUR.0.4.profile\n",
      "-rw-rw-r-- 1 hmiwa hmiwa    25672 11月 13 14:19 EUR.0.5.profile\n",
      "-rw-rw-r-- 1 hmiwa hmiwa  7021061 11月 13 12:22 EUR.a1\n",
      "-rw-rw-r-- 1 hmiwa hmiwa   171939 11月 13 15:50 \u001b[0m\u001b[01;35mEUR_BARPLOT_2023-11-13.png\u001b[0m\n",
      "-rw-r--r-- 1 hmiwa hmiwa 69538395  7月 24  2020 EUR.bed\n",
      "-rw-rw-r-- 1 hmiwa hmiwa    16984 11月 13 15:50 EUR.best\n",
      "-rw-r--r-- 1 hmiwa hmiwa 18795810  7月 24  2020 EUR.bim\n",
      "-rw-rw-r-- 1 hmiwa hmiwa 18572000 11月 13 14:04 EUR.clumped\n",
      "-rw-r----- 1 hmiwa hmiwa     9066  7月 24  2020 EUR.cov\n",
      "-rw-rw-r-- 1 hmiwa hmiwa    39992 11月 13 15:49 EUR.covariate\n",
      "-rw-rw-r-- 1 hmiwa hmiwa       46 11月 13 14:23 EUR.eigenval\n",
      "-rw-rw-r-- 1 hmiwa hmiwa    38990 11月 13 14:23 EUR.eigenvec\n",
      "-rw-r--r-- 1 hmiwa hmiwa    12575  7月 24  2020 EUR.fam\n",
      "-rw-r----- 1 hmiwa hmiwa    15642  7月 24  2020 EUR.height\n",
      "-rw-rw-r-- 1 hmiwa hmiwa   158784 11月 13 15:50 \u001b[01;35mEUR_HIGH-RES_PLOT_2023-11-13.png\u001b[0m\n",
      "-rw-rw-r-- 1 hmiwa hmiwa     2447 11月 13 15:50 EUR.log\n",
      "-rw-rw-r-- 1 hmiwa hmiwa   678351 11月 13 12:22 EUR.mismatch\n",
      "-rw-rw-r-- 1 hmiwa hmiwa  5075148 11月 13 14:18 EUR.nopred\n",
      "-rw-rw-r-- 1 hmiwa hmiwa   579785 11月 13 15:50 EUR.prsice\n",
      "-rw-rw-r-- 1 hmiwa hmiwa  2734929 11月 13 14:23 EUR.prune.in\n",
      "-rw-rw-r-- 1 hmiwa hmiwa  2501932 11月 13 14:23 EUR.prune.out\n",
      "-rw-rw-r-- 1 hmiwa hmiwa 59266408 11月 13 12:39 EUR.QC.bed\n",
      "-rw-rw-r-- 1 hmiwa hmiwa 16768162 11月 13 12:39 EUR.QC.bim\n",
      "-rw-rw-r-- 1 hmiwa hmiwa    12075 11月 13 12:39 EUR.QC.fam\n",
      "-rw-r--r-- 1 hmiwa hmiwa    35280 11月 13 02:57 EUR.QC.het\n",
      "-rw-rw-r-- 1 hmiwa hmiwa    15268 11月 13 12:26 EUR.QC.hh\n",
      "-rw-rw-r-- 1 hmiwa hmiwa      224 11月 13 02:51 EUR.QC.irem\n",
      "-rw-rw-r-- 1 hmiwa hmiwa     1060 11月 13 12:39 EUR.QC.log\n",
      "-rw-rw-r-- 1 hmiwa hmiwa  2892363 11月 13 02:55 EUR.QC.prune.in\n",
      "-rw-rw-r-- 1 hmiwa hmiwa  2898004 11月 13 02:55 EUR.QC.prune.out\n",
      "-rw-rw-r-- 1 hmiwa hmiwa     7728 11月 13 12:34 EUR.QC.rel.id\n",
      "-rw-rw-r-- 1 hmiwa hmiwa    35136 11月 13 12:26 EUR.QC.sexcheck\n",
      "-rw-rw-r-- 1 hmiwa hmiwa  5790367 11月 13 02:51 EUR.QC.snplist\n",
      "-rw-rw-r-- 1 hmiwa hmiwa     7728 11月 13 12:28 EUR.QC.valid\n",
      "-rw-rw-r-- 1 hmiwa hmiwa      171 11月 13 15:50 EUR.summary\n",
      "-rw-rw-r-- 1 hmiwa hmiwa     7800 11月 13 03:03 EUR.valid.sample\n",
      "-rw-rw-r-- 1 hmiwa hmiwa  2104430 11月 13 14:10 EUR.valid.snp\n",
      "-rw-rw-r-- 1 hmiwa hmiwa 38407531 11月 13 02:38 \u001b[01;31mEUR.zip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ls -l EUR*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cb59964f-6c8c-4e7b-a8d0-4481056676f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2023-11-13 15:49:56\n",
      "./PRSice_linux \\\n",
      "    --a1 A1 \\\n",
      "    --a2 A2 \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base Height.QC.gz \\\n",
      "    --base-info INFO:0.8 \\\n",
      "    --base-maf MAF:0.01 \\\n",
      "    --binary-target F \\\n",
      "    --bp BP \\\n",
      "    --chr CHR \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov EUR.covariate \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --or  \\\n",
      "    --out EUR \\\n",
      "    --pheno EUR.height \\\n",
      "    --pvalue P \\\n",
      "    --seed 3154700390 \\\n",
      "    --snp SNP \\\n",
      "    --stat OR \\\n",
      "    --target EUR.QC \\\n",
      "    --thread 1 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: EUR.QC (bed) \n",
      "\n",
      "Start processing Height.QC \n",
      "================================================== \n",
      "\n",
      "Base file: Height.QC.gz \n",
      "GZ file detected. Header of file is: \n",
      "CHR\tBP\tSNP\tA1\tA2\tN\tSE\tP\tOR\tINFO\tMAF \n",
      "\n",
      "499617 variant(s) observed in base file, with: \n",
      "499617 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "483 people (232 male(s), 251 female(s)) observed \n",
      "483 founder(s) included \n",
      "\n",
      "489805 variant(s) included \n",
      "\n",
      "Phenotype file: EUR.height \n",
      "Column Name of Sample ID: FID+IID \n",
      "Note: If the phenotype file does not contain a header, the \n",
      "column name will be displayed as the Sample ID which is \n",
      "expected. \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Number of variant(s) after clumping : 193758 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Height is a continuous phenotype \n",
      "11 sample(s) without phenotype \n",
      "472 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: EUR.covariate \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "Sex\t0\t- \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "\n",
      "After reading the covariate file, 472 sample(s) included in \n",
      "the analysis \n",
      "\n",
      "There are 1 region(s) with p-value less than 1e-5. Please \n",
      "note that these results are inflated due to the overfitting \n",
      "inherent in finding the best-fit PRS (but it's still best \n",
      "to find the best-fit PRS!). \n",
      "You can use the --perm option (see manual) to calculate an \n",
      "empirical P-value. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat EUR.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167fb05f-4592-4873-afba-fe01d9d81ec1",
   "metadata": {},
   "source": [
    "This will automatically perform \"high-resolution scoring\" and generate the \"best-fit\" PRS (in EUR.best), with associated plots of the results. Users should read Section 4.6 of our paper to learn more about issues relating to overfitting in PRS analyses.\n",
    "\n",
    "これにより、自動的に「高解像度スコアリング」が実行され、「ベストフィット」PRS（EUR.best）が生成され、関連する結果のプロットが表示される。PRS分析におけるオーバーフィットに関する問題については、本稿のセクション4.6をお読みください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "25cc8a90-404b-40fa-8a87-994dd9b6ffe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID IID In_Regression PRS\n",
      "HG00096 HG00096 Yes -2.11096839e-05\n",
      "HG00097 HG00097 Yes 1.18283984e-05\n",
      "HG00099 HG00099 Yes -3.21465115e-06\n",
      "HG00101 HG00101 Yes 1.00652688e-05\n",
      "HG00102 HG00102 Yes 1.88213352e-05\n",
      "HG00103 HG00103 Yes 1.95660119e-05\n",
      "HG00105 HG00105 Yes 5.83885412e-06\n",
      "HG00107 HG00107 Yes 1.6817274e-06\n",
      "HG00108 HG00108 Yes 1.44980367e-05\n",
      "HG00109 HG00109 Yes 1.21884277e-05\n",
      "HG00110 HG00110 No 1.42346463e-05\n",
      "HG00111 HG00111 Yes 1.14101217e-05\n",
      "HG00112 HG00112 Yes 1.31346962e-06\n",
      "HG00113 HG00113 Yes 7.34236439e-06\n"
     ]
    }
   ],
   "source": [
    "cat EUR.best | head -n 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4bc77314-d5e5-4b0c-8e12-0dd837e301fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pheno\tSet\tThreshold\tR2\tP\tCoefficient\tStandard.Error\tNum_SNP\n",
      "-\tBase\t5e-08\t0.0187543\t0.000759454\t512.095\t151.092\t1999\n",
      "-\tBase\t5.005e-05\t0.0564623\t3.25037e-09\t2749.86\t455.786\t7615\n",
      "-\tBase\t0.00010005\t0.06536\t1.68427e-10\t3420.63\t523.687\t9047\n",
      "-\tBase\t0.00015005\t0.0719174\t1.86697e-11\t3915.75\t568.857\t10014\n",
      "-\tBase\t0.00020005\t0.073223\t1.20254e-11\t4193.76\t603.227\t10756\n",
      "-\tBase\t0.00025005\t0.0752322\t6.10257e-12\t4447.27\t630.188\t11365\n",
      "-\tBase\t0.00030005\t0.0749899\t6.62325e-12\t4617.44\t655.471\t11884\n",
      "-\tBase\t0.00035005\t0.076828\t3.55674e-12\t4849.54\t679.24\t12373\n",
      "-\tBase\t0.00040005\t0.0780733\t2.33224e-12\t5026.71\t697.793\t12817\n"
     ]
    }
   ],
   "source": [
    "head EUR.prsice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "04daa650-669b-4e2e-886f-fce7a8732ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phenotype\tSet\tThreshold\tPRS.R2\tFull.R2\tNull.R2\tPrevalence\tCoefficient\tStandard.Error\tP\tNum_SNP\n",
      "-\tBase\t0.13995\t0.162601\t0.38795\t0.225349\t-\t34375.6\t3099.5\t1.47008e-25\t85982\n"
     ]
    }
   ],
   "source": [
    "head EUR.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "76ee62b5-7353-454b-b2b0-20f46abb12ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p ~/hmiwa/hmiwa-lab/d_20231023/03_231113_TutorialPRS/pic\n",
    "cp *.png ~/hmiwa/hmiwa-lab/d_20231023/03_231113_TutorialPRS/pic/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "465f3021-1172-40c3-a875-32236a4600c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;35mEUR_BARPLOT_2023-11-13.png\u001b[0m  \u001b[01;35mEUR_HIGH-RES_PLOT_2023-11-13.png\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ls ~/hmiwa/hmiwa-lab/d_20231023/03_231113_TutorialPRS/pic/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092d0b13-95f7-4cba-bea9-16b407985b88",
   "metadata": {},
   "source": [
    "<img src=\"pic/EUR_BARPLOT_2023-11-13.png\" width=49%> <img src=\"pic/EUR_HIGH-RES_PLOT_2023-11-13.png\" width=49%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5054a253-075d-469b-8916-1954b11a7a87",
   "metadata": {},
   "source": [
    "## 4. Visualizing PRS Results\n",
    "\n",
    "### Plotting the Results\n",
    "The PRS results corresponding to a range of P-value thresholds obtained by application of the C+T PRS method (eg. using PLINK or PRSice-2) can be visualised using R as follows:\n",
    "\n",
    "C+T PRS法（例えばPLINKやPRSice-2を使用）を適用して得られたP値のしきい値の範囲に対応するPRS結果は、以下のようにRを使用して可視化することができる：\n",
    "\n",
    ">We will be using prs.result variable, which was generated in the previous section\n",
    ">\n",
    ">前のセクションで生成されたprs.result変数を使用する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3cae3741-42a6-4652-811f-200c8c7b88b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Threshold        R2           P     BETA       SE\n",
      "5       0.3 0.1612372 2.77407e-25 45316.19 4107.777\n",
      "\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "cat <<EOL > ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data/PRSplot1.R\n",
    "p.threshold <- c(0.001,0.05,0.1,0.2,0.3,0.4,0.5)\n",
    "# Read in the phenotype file \n",
    "phenotype <- read.table(\"EUR.height\", header=T)\n",
    "# Read in the PCs\n",
    "pcs <- read.table(\"EUR.eigenvec\", header=F)\n",
    "# The default output from plink does not include a header\n",
    "# To make things simple, we will add the appropriate headers\n",
    "# (1:6 because there are 6 PCs)\n",
    "colnames(pcs) <- c(\"FID\", \"IID\", paste0(\"PC\",1:6)) \n",
    "# Read in the covariates (here, it is sex)\n",
    "covariate <- read.table(\"EUR.cov\", header=T)\n",
    "# Now merge the files\n",
    "pheno <- merge(merge(phenotype, covariate, by=c(\"FID\", \"IID\")), pcs, by=c(\"FID\",\"IID\"))\n",
    "# We can then calculate the null model (model with PRS) using a linear regression \n",
    "# (as height is quantitative)\n",
    "null.model <- lm(Height~., data=pheno[,!colnames(pheno)%in%c(\"FID\",\"IID\")])\n",
    "# And the R2 of the null model is \n",
    "null.r2 <- summary(null.model)\\$r.squared\n",
    "prs.result <- NULL\n",
    "for(i in p.threshold){\n",
    "    # Go through each p-value threshold\n",
    "    prs <- read.table(paste0(\"EUR.\",i,\".profile\"), header=T)\n",
    "    # Merge the prs with the phenotype matrix\n",
    "    # We only want the FID, IID and PRS from the PRS file, therefore we only select the \n",
    "    # relevant columns\n",
    "    pheno.prs <- merge(pheno, prs[,c(\"FID\",\"IID\", \"SCORE\")], by=c(\"FID\", \"IID\"))\n",
    "    # Now perform a linear regression on Height with PRS and the covariates\n",
    "    # ignoring the FID and IID from our model\n",
    "    model <- lm(Height~., data=pheno.prs[,!colnames(pheno.prs)%in%c(\"FID\",\"IID\")])\n",
    "    # model R2 is obtained as \n",
    "    model.r2 <- summary(model)\\$r.squared\n",
    "    # R2 of PRS is simply calculated as the model R2 minus the null R2\n",
    "    prs.r2 <- model.r2-null.r2\n",
    "    # We can also obtain the coeffcient and p-value of association of PRS as follow\n",
    "    prs.coef <- summary(model)\\$coeff[\"SCORE\",]\n",
    "    prs.beta <- as.numeric(prs.coef[1])\n",
    "    prs.se <- as.numeric(prs.coef[2])\n",
    "    prs.p <- as.numeric(prs.coef[4])\n",
    "    # We can then store the results\n",
    "    prs.result <- rbind(prs.result, data.frame(Threshold=i, R2=prs.r2, P=prs.p, BETA=prs.beta,SE=prs.se))\n",
    "}\n",
    "# Best result is:\n",
    "prs.result[which.max(prs.result\\$R2),]\n",
    "\n",
    "# ggplot2 is a handy package for plotting\n",
    "library(ggplot2)\n",
    "# generate a pretty format for p-value output\n",
    "prs.result\\$print.p <- round(prs.result\\$P, digits = 3)\n",
    "prs.result\\$print.p[!is.na(prs.result\\$print.p) &\n",
    "                    prs.result\\$print.p == 0] <-\n",
    "    format(prs.result\\$P[!is.na(prs.result\\$print.p) &\n",
    "                            prs.result\\$print.p == 0], digits = 2)\n",
    "prs.result\\$print.p <- sub(\"e\", \"*x*10^\", prs.result\\$print.p)\n",
    "# Initialize ggplot, requiring the threshold as the x-axis (use factor so that it is uniformly distributed)\n",
    "ggplot(data = prs.result, aes(x = factor(Threshold), y = R2)) +\n",
    "    # Specify that we want to print p-value on top of the bars\n",
    "    geom_text(\n",
    "        aes(label = paste(print.p)),\n",
    "        vjust = -1.5,\n",
    "        hjust = 0,\n",
    "        angle = 45,\n",
    "        cex = 4,\n",
    "        parse = T\n",
    "    )  +\n",
    "    # Specify the range of the plot, *1.25 to provide enough space for the p-values\n",
    "    scale_y_continuous(limits = c(0, max(prs.result\\$R2) * 1.25)) +\n",
    "    # Specify the axis labels\n",
    "    xlab(expression(italic(P) - value ~ threshold ~ (italic(P)[T]))) +\n",
    "    ylab(expression(paste(\"PRS model fit:  \", R ^ 2))) +\n",
    "    # Draw a bar plot\n",
    "    geom_bar(aes(fill = -log10(P)), stat = \"identity\") +\n",
    "    # Specify the colors\n",
    "    scale_fill_gradient2(\n",
    "        low = \"dodgerblue\",\n",
    "        high = \"firebrick\",\n",
    "        mid = \"dodgerblue\",\n",
    "        midpoint = 1e-4,\n",
    "        name = bquote(atop(-log[10] ~ model, italic(P) - value),)\n",
    "    ) +\n",
    "    # Some beautification of the plot\n",
    "    theme_classic() + theme(\n",
    "        axis.title = element_text(face = \"bold\", size = 18),\n",
    "        axis.text = element_text(size = 14),\n",
    "        legend.title = element_text(face = \"bold\", size =\n",
    "                                        18),\n",
    "        legend.text = element_text(size = 14),\n",
    "        axis.text.x = element_text(angle = 45, hjust =\n",
    "                                    1)\n",
    "    )\n",
    "# save the plot\n",
    "ggsave(\"EUR.height.bar.png\", height = 7, width = 7)\n",
    "EOL\n",
    "cd ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data/\n",
    "Rscript ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data/PRSplot1.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bf4fd325-cbc4-43dd-9446-472e14e1d390",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp EUR.height.bar.png ~/hmiwa/hmiwa-lab/d_20231023/03_231113_TutorialPRS/pic/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62233513-b771-4d3e-9556-a22d3f8e0fb7",
   "metadata": {},
   "source": [
    "<img src=\"pic/EUR.height.bar.png\" width=49%>\n",
    "\n",
    "例と数値が多少違うがこれで良いのかな"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399c3838-479b-4ec7-86a1-99092bbcd6d6",
   "metadata": {},
   "source": [
    "In addition, we can visualise the relationship between the \"best-fit\" PRS (which may have been obtained from any of the PRS programs) and the phenotype of interest, coloured according to sex:\n",
    "\n",
    "さらに、\"ベストフィット \"PRS（どのPRSプログラムからも取得可能）と目的の表現型との関係を、性別に応じて色分けして可視化することができる："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3d04d6c5-552c-4822-9423-b894c4f8e774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "cat <<EOL > ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data/PRSplot2.R\n",
    "library(ggplot2)\n",
    "# Read in the files\n",
    "prs <- read.table(\"EUR.0.3.profile\", header=T)\n",
    "height <- read.table(\"EUR.height\", header=T)\n",
    "sex <- read.table(\"EUR.cov\", header=T)\n",
    "# Rename the sex\n",
    "sex\\$Sex <- as.factor(sex\\$Sex)\n",
    "levels(sex\\$Sex) <- c(\"Male\", \"Female\")\n",
    "# Merge the files\n",
    "dat <- merge(merge(prs, height), sex)\n",
    "# Start plotting\n",
    "ggplot(dat, aes(x=SCORE, y=Height, color=Sex))+\n",
    "    geom_point()+\n",
    "    theme_classic()+\n",
    "    labs(x=\"Polygenic Score\", y=\"Height\")\n",
    "ggsave(\"EUR.height.scatter.png\", height = 7, width = 7)\n",
    "EOL\n",
    "Rscript ~/hmiwa1/storage/hmiwa-lab/03_231113_TutorialPRS/data/PRSplot2.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0c43267b-a01c-4673-a9f6-dfad60a4cbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp EUR.height.scatter.png ~/hmiwa/hmiwa-lab/d_20231023/03_231113_TutorialPRS/pic/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e79e1b-71b7-4d09-8653-ce5e3de941ab",
   "metadata": {},
   "source": [
    "<img src=\"pic/EUR.height.scatter.png\" width=49%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f485814-4dbd-4951-94df-c9fdbde69f60",
   "metadata": {},
   "source": [
    "Programs such as PRSice-2 and bigsnpr include numerous options for plotting PRS results.\n",
    "\n",
    "PRSice-2やbigsnprなどのプログラムには、PRSの結果をプロットするための多くのオプションが用意されている。\n",
    "\n",
    "**BasicなPRSチュートリアルはここまで！よくできました**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
